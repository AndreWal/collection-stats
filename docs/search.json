[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "From Beta to Meaning: A Guide to Interpreting Regression Analysis",
    "section": "",
    "text": "0.1 Why this collection?\nThis collection is a work-in-progress. New articles will be added over time.\nWhy publish another set of articles on statistics when there are already many excellent resources? There are strong introductions at every level, mathematical, applied, and software-focused, and many are freely available. Some emphasize theory and proofs; others emphasize implementation in R, Python, Stata, or SQL; still others are field-specific (biostatistics, engineering, economics, business, and more).\nThis collection exists for two reasons.\nFirst, the skill mix in quantitative work is changing. AI coding assistants can already generate a large share of routine statistical code quickly, and this capability is improving fast. As a result, the comparative advantage of researchers and data analysts is shifting away from writing every line by hand and toward:\nIn other words, implementation still matters, but interpretation, judgment, and communication matter even more.\nSecond, I wanted to build the resource I wish I had during my PhD. Traditional textbooks taught the formal material well, but many practical research decisions were left implicit: Which method is appropriate here? What trade-offs am I making? What can go wrong in real data? How should results be interpreted and communicated?\nThese articles aim to close that gap. They connect core statistical ideas to real research workflows, with concise explanations, worked examples, and decision-oriented guidance.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>From Beta to Meaning</span>"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "2  Preface",
    "section": "",
    "text": "2.1 Prerequisites\nThis preface explains why the book exists and how it is organized.\nHigh school level math. It is helpful if you have some experience with R so you understand the code snippets, but it is not necessary to understand the issues that I try to address in this book.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Preface</span>"
    ]
  },
  {
    "objectID": "preface.html#how-to-use-this-book",
    "href": "preface.html#how-to-use-this-book",
    "title": "2  Preface",
    "section": "2.2 How to use this book",
    "text": "2.2 How to use this book\nAll data used in this book is simulated. Even though the goal of the book is not to demonstrate how to use a statistical software, code snippets are included to illustrate how to implement the methods discussed in the book. The code is written in R, but the concepts can be applied in other programming languages as well. The code snippets are meant to be illustrative and are not intended to be comprehensive or optimized for performance. Readers are encouraged to experiment with the code and adapt it to their own needs.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Preface</span>"
    ]
  },
  {
    "objectID": "chapters/01-introduction.html",
    "href": "chapters/01-introduction.html",
    "title": "2  Introduction",
    "section": "",
    "text": "2.1 Why this book\nWhy another book on statistics? There are already many excellent introductions, both technical and non-technical, and many are freely available online. Some focus on the mathematical foundations of statistics, while others provide practical guidance on applying statistical methods across contexts or implementing them in software such as R, Python, or Stata. Still others are tailored to specific disciplines and industries such as health and biostatistics, engineering, economics, and business. So why write another one?\nThere are two reasons why I decided to write this book. First, coding and implementing statistics into software is a skill that is likely to become less important with the arrival of AI-coding assistants. Most agents such as Claude Code or Codex can write better code in R, SQL, Python or other languages than most humans, and they can do it much faster. While some coding skills will still be necessary to understand how to use these tools as well as to debug and adjust code for specific use cases, the need to write code from scratch will likely diminish over time. What will become more important, however, is the ability to clearly communicate what a user wants an agent to do and how to understand and interpret the results that an agent produces.\nThis brings me to the second reason for writing this book. The book is also going to be the book that I hoped I had when I was learning statistics and doing research as a PhD student. While there were many great books on statistics already available, I found that there were a lot of open questions when doing quantitative research that were not covered in these books.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/01-introduction.html#roadmap",
    "href": "chapters/01-introduction.html#roadmap",
    "title": "2  Introduction",
    "section": "2.2 Roadmap",
    "text": "2.2 Roadmap\nOutline the main themes and how the chapters connect.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/02-chapter-one.html",
    "href": "chapters/02-chapter-one.html",
    "title": "4  Categorical and Compositional Predictors: A Guide",
    "section": "",
    "text": "4.1 Binary Predictor Variables\nDisclaimer: All data used in this chapter is simulated and does not reflect real-world data. The purpose of this chapter is to illustrate the concept of categorical and compositional predictors in regression analysis, not to make any claims about the relationship between gender, party identification, and political donations or party shares and social spending.\nI already discussed how to interpret coefficients in a regression model. What I have not discussed is that the interpretation of a coefficient as the expected change in the response variable for a one-unit increase in the predictor variable (holding all other predictors constant) is most direct when a one-unit change is substantively meaningful. For binary and categorical predictors, coefficients are instead interpreted as differences between categories defined by the coding scheme. This has consequences for how we specify models and interpret results as I will show in the following.\nSuppose I study the relationship between gender and political donations. I have a binary variable gender coded 0 for men and 1 for women and donationAmount in US dollars. To understand how categorical variables work in regression analysis, I start by computing the average donation amount for men and women:\nmean_donation &lt;- aggregate(donationAmount ~ gender, data = data, FUN = mean)\nmean_donation$gender &lt;- c(\"Men\", \"Women\")\ncolnames(mean_donation) &lt;- c(\"Gender\", \"Mean Donation Amount\")\nknitr::kable(mean_donation, digits = 2)\n\n\n\n\nGender\nMean Donation Amount\n\n\n\n\nMen\n98.75\n\n\nWomen\n148.22\nAs the table shows, men donate on average 98.75 dollars, while women donate on average 148.22 dollars. With that in mind, I estimate a regression model with donationAmount as the response variable and gender as the predictor variable. Mathematically, the model can be written as follows:\n\\[donationAmount_i = \\alpha_0 + \\beta_1 gender_i + \\epsilon_i\\]\nIn R, I estimate the model using the lm() function:\nlm(donationAmount ~ factor(gender), data = data)\n\n\nCall:\nlm(formula = donationAmount ~ factor(gender), data = data)\n\nCoefficients:\n    (Intercept)  factor(gender)1  \n          98.75            49.46\nI start with the interpretation of the results before digging deeper. The coefficient for gender is about 50. In the case of a binary variable, the interpretation is straightforward: The coefficient compares the coded group (1) to the reference group (0). More precisely, the coefficient of about 50 for gender means that women donate on average 50 dollars more than men.\nComparing the regression output to the means table, I can highlight two points. First, the coefficient of the intercept is about 98.75, which is the average donation amount for men. Put differently, the intercept equals the mean of the reference category of men in this specification because, more generally, the intercept is the expected outcome when all predictors are zero and factors are at their baseline levels. This can be expressed mathematically:\n\\[E(donationAmount \\mid \\text{men}) = \\alpha_0\\]\nThis is why, when the model includes an intercept, one category must be omitted; otherwise the full set of dummies is perfectly collinear with the intercept (the dummy-variable trap). That means that if I included binary variables for both men and women in the model, the dummy variables would be perfectly collinear with the intercept and the model would not be estimable.\nSecond, the coefficient for gender is about 50, which is the difference in mean donation amounts between men and women. Thus, the coefficient for gender does not give us the average donation amount for women, but rather the difference in average donation amounts between women and men. In turn, this means that the mean donation amount of women is the sum of the coefficient of the intercept and the coefficient for gender:\n\\[E(donationAmount \\mid \\text{women}) = \\alpha_0 + \\beta_1\\]\nLastly, the substantive interpretation of the results does not change if I alter the reference category. With pure releveling (changing only which category is omitted), fitted values and model fit stay the same, but coefficient labels and interpretations change. To illustrate this, I can relevel the gender variable so that women are the reference category and are omitted from the model:\nlm(donationAmount ~ relevel(factor(gender), ref = \"1\"), data = data)\n\n\nCall:\nlm(formula = donationAmount ~ relevel(factor(gender), ref = \"1\"), \n    data = data)\n\nCoefficients:\n                        (Intercept)  relevel(factor(gender), ref = \"1\")0  \n                             148.22                               -49.46\nAs shown, the coefficient for intercept is now about 148, which is equal to the average donation amount for women according to the means table. The coefficient for gender (level 0) now displays the difference in donation amount of men compared to women. More precisely, it is now about -50, meaning that men donate on average 50 dollars less than women. Again, summing the coefficient of the intercept and the coefficient for gender gives the average donation amount for men. Thus, while the coefficients of intercept and gender have changed, the substantive interpretation of the results has not. The choice of reference category does not affect the substantive interpretation of the results, but it does affect how the coefficients are read.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Categorical and Compositional Predictors: A Guide</span>"
    ]
  },
  {
    "objectID": "chapters/03-chapter-two.html",
    "href": "chapters/03-chapter-two.html",
    "title": "4  Context Matters: A Guide to Interaction Terms",
    "section": "",
    "text": "4.1 Interaction Terms as Context\nDisclaimer: All data used in this chapter is simulated and does not reflect real-world data. The purpose of this chapter is to illustrate the concept of interaction terms in linear regression models, not to make any claims about the relationship between age, income, and ideological placement.\nResearchers often want to know whether relationships differ across contexts. We use ideological self-placement as the running example. More specifically, I want to know whether age affects left-right self-placement. In addition, I assume that income affects ideological leanings as well, meaning that voters at the lower end of the income distribution are typically more left than voters on the higher end of the income distribution. So, how can interaction terms help us understand the relationship between age, income and ideological placement? Does the relationship between age and ideological placement differ across income levels? If so, how can we model this relationship?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Context Matters: A Guide to Interaction Terms</span>"
    ]
  },
  {
    "objectID": "chapters/03-chapter-two.html#what-is-an-interaction-term",
    "href": "chapters/03-chapter-two.html#what-is-an-interaction-term",
    "title": "4  Context Matters: A Guide to Interaction Terms",
    "section": "4.2 What is an Interaction Term?",
    "text": "4.2 What is an Interaction Term?\nIn this example, income is measured in tens of thousands, and leftRight is a 0-10 self-placement scale where higher values indicate more right-leaning views.\nWe established in the previous chapter that a coefficient in a regression model represents the average effect of a predictor variable on the response variable, holding all other variables constant. However, this assumes that the effect of the predictor is the same across all contexts. Using a linear regression model with a continuous response variable leftRight and a predictor variable age, we can illustrate this point. Mathematically, our model without an interaction term looks as follows:\n\\[\nleftRight_i = \\alpha + \\beta_1 age_i + \\epsilon_i\n\\tag{4.1}\\]\nEquation 4.1 shows that the marginal effect of a predictor variable in a linear regression model is represented by the coefficient \\(\\beta_1\\). To understand interactions, it is helpful to know that the marginal effect of a predictor can be read directly from the equation because it is the partial derivative of the response variable with respect to the predictor variable. In our simple regression model, the marginal effect of age is \\(\\beta_1\\), which means that for every one-unit increase in age, the expected change in leftRight is \\(\\beta_1\\) units. Mathematically, the partial derivative of Equation 4.1 can be expressed as: \\[\n\\frac{\\partial leftRight_i}{\\partial age_i} = \\beta_1\n\\tag{4.2}\\]\nIn R, this model can be estimated using the lm() function as follows:\n\nsummary(\n  lm(leftRight ~ age, data = data)\n)\n\n\nCall:\nlm(formula = leftRight ~ age, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.5059 -0.8757 -0.0084  0.9727  3.0922 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 3.697214   0.118956   31.08   &lt;2e-16 ***\nage         0.045269   0.002289   19.78   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.289 on 998 degrees of freedom\nMultiple R-squared:  0.2816,    Adjusted R-squared:  0.2809 \nF-statistic: 391.3 on 1 and 998 DF,  p-value: &lt; 2.2e-16\n\n\nSo, why is this important to understand interaction terms? An interaction term is essentially a multiplicative combination of two predictor variables. When we include an interaction term in our regression model, we simply add two predictors and their product to the equation. Let’s assume that we want to know whether the effect of age on leftRight depends on the income of a respondent. Our regression model with the interaction term would look like this: \\[\nleftRight_i = \\alpha + \\beta_1 age_i + \\beta_2 income_i + \\beta_3 (age_i \\times income_i) + \\epsilon_i\n\\tag{4.3}\\]\nIf we take the partial derivative of Equation 4.3 with respect to age, we get: \\[\n\\frac{\\partial leftRight_i}{\\partial age_i} = \\beta_1 + \\beta_3 income_i\n\\tag{4.4}\\]\nAs Equation 4.4 shows, the effect of age on leftRight is no longer constant but depends on the value of income. The coefficient \\(\\beta_3\\) represents the change in the effect of age for each one-unit increase in income. If \\(\\beta_3\\) is positive, it means that the effect of age on leftRight increases as income increases. Conversely, if \\(\\beta_3\\) is negative, it means that the effect of age on leftRight decreases as income increases.\nIn R, this would look like this:\n\nsummary(\n  lm(leftRight ~ age * income, data = data)\n)\n\n\nCall:\nlm(formula = leftRight ~ age * income, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.45589 -0.55774  0.02019  0.56182  2.66821 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 2.4255133  0.2030559  11.945  &lt; 2e-16 ***\nage         0.0224525  0.0038078   5.896 5.08e-09 ***\nincome      0.1625065  0.0264208   6.151 1.12e-09 ***\nage:income  0.0037022  0.0005002   7.401 2.86e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8063 on 996 degrees of freedom\nMultiple R-squared:  0.7196,    Adjusted R-squared:  0.7187 \nF-statistic: 851.9 on 3 and 996 DF,  p-value: &lt; 2.2e-16\n\n\n(R adds the constitutive terms automatically when you use the * operator between two variables in the formula.)\nEven though it is more informative to plot the interaction to understand how the effect of age changes across different income levels, we can also look at the coefficients to get a sense of the interaction. First, we can see that the coefficient for age is positive. However, the coefficient for age gives us only the effect of age when income is zero, which is not a meaningful value in this context. A solution here would be to center the income variable around its mean before including it in the regression model. This way, the coefficient for age would represent the effect of age at the average income level.\nSecond, the coefficient for the interaction term age:income is positive, which indicates that the effect of age on leftRight increases as income increases. This means that age is more strongly associated with rightward placement among higher-income respondents than among lower-income respondents. Therefore, the table alone already gives us a pretty good idea of the interaction, but it is often more intuitive to visualize it:\n\n# Fit the model with interaction\nmodel &lt;- lm(leftRight ~ age * income, data = data)\n\n# Extract coefficients and variance-covariance matrix\ncoefs &lt;- coef(model)\nvcov_matrix &lt;- vcov(model)\n\nincome_seq &lt;- seq(2, 12, length.out = 100)\n\neffect &lt;- coefs[2] + coefs[4] * income_seq\n\nse &lt;- sqrt(vcov_matrix[2, 2] + \n           income_seq^2 * vcov_matrix[4, 4] + \n           2 * income_seq * vcov_matrix[2, 4])\n\nci_lower &lt;- effect - 1.96 * se\nci_upper &lt;- effect + 1.96 * se\n\n# Create plot\nplot(income_seq, effect, \n     type = \"l\", \n     lwd = 2,\n     ylim = c(min(ci_lower), max(ci_upper)),\n  xlab = \"Income (tens of thousands)\",\n  ylab = \"Effect of Age on Left-Right Placement\",\n  main = \"Marginal Effect of Age by Income\\n(with 95% Confidence Intervals)\")\n\n# Add confidence interval as shaded region\npolygon(c(income_seq, rev(income_seq)), \n        c(ci_upper, rev(ci_lower)),\n        col = rgb(0.2, 0.2, 0.8, 0.2),\n        border = NA)\n\n# Add reference line at y=0\nabline(h = 0, lty = 2, col = \"gray\", lwd = 1)\n\n# Re-plot the line on top\nlines(income_seq, effect, lwd = 2, col = \"blue\")\n\n\n\n\n\n\n\n\nTo plot the marginal effect of age on leftRight across different income levels, along with 95% confidence intervals, we use the coefficients and variance-covariance matrix from the fitted model. To compute variance for the confidence intervals, we apply the delta method:\n\\[Var(\\beta_1 + \\beta_3 \\cdot income) = Var(\\beta_1) + income^2 \\cdot Var(\\beta_3) + 2 \\cdot income \\cdot Cov(\\beta_1, \\beta_3)\\]\nThe plot shows that the estimated effect of age is positive across the observed income range. This visualization gives us a much clearer picture of how the effect of age changes across income levels compared to a regression table. While age increases rightward placement for all income levels, the effect is much stronger for higher-income respondents than for lower-income respondents.\nAn alternative way to visualize the interaction is to plot predicted values of leftRight across age for different income levels. To do so, we use the 10%, 50%, and 90% quantiles of the income variable to represent low, medium, and high income levels, respectively. We then plot the predicted leftRight values across age for these three income levels, along with confidence intervals.\n\nincome_levels &lt;- as.numeric(quantile(data$income, probs = c(0.1, 0.5, 0.9)))\nincome_labels &lt;- paste0(c(\"P10 = \", \"P50 = \", \"P90 = \"), sprintf(\"%.1f\", income_levels))\nage_grid &lt;- seq(18, 80, length.out = 100)\n\npred_grid &lt;- expand.grid(\n  age = age_grid,\n  income = income_levels\n)\n\npred_ci &lt;- predict(model, newdata = pred_grid, interval = \"confidence\")\npred_grid$leftRight_hat &lt;- pred_ci[, \"fit\"]\npred_grid$ci_lower &lt;- pred_ci[, \"lwr\"]\npred_grid$ci_upper &lt;- pred_ci[, \"upr\"]\n\nplot(age_grid, pred_grid$leftRight_hat[pred_grid$income == income_levels[1]],\n     type = \"l\",\n     lwd = 2,\n     ylim = range(pred_grid$ci_lower, pred_grid$ci_upper),\n     xlab = \"Age\",\n     ylab = \"Predicted Left-Right Placement\",\n    main = \"Predicted Left-Right by Age\\n(at Income P10, P50, and P90)\")\n\npolygon(c(age_grid, rev(age_grid)),\n        c(pred_grid$ci_upper[pred_grid$income == income_levels[1]],\n          rev(pred_grid$ci_lower[pred_grid$income == income_levels[1]])),\n        col = rgb(0, 0, 0, 0.15),\n        border = NA)\n\nlines(age_grid, pred_grid$leftRight_hat[pred_grid$income == income_levels[2]], lwd = 2, col = \"blue\")\nlines(age_grid, pred_grid$leftRight_hat[pred_grid$income == income_levels[3]], lwd = 2, col = \"red\")\n\npolygon(c(age_grid, rev(age_grid)),\n        c(pred_grid$ci_upper[pred_grid$income == income_levels[2]],\n          rev(pred_grid$ci_lower[pred_grid$income == income_levels[2]])),\n        col = rgb(0, 0, 1, 0.15),\n        border = NA)\n\npolygon(c(age_grid, rev(age_grid)),\n        c(pred_grid$ci_upper[pred_grid$income == income_levels[3]],\n          rev(pred_grid$ci_lower[pred_grid$income == income_levels[3]])),\n        col = rgb(1, 0, 0, 0.15),\n        border = NA)\n\nlines(age_grid, pred_grid$leftRight_hat[pred_grid$income == income_levels[1]], lwd = 2, col = \"black\")\nlines(age_grid, pred_grid$leftRight_hat[pred_grid$income == income_levels[2]], lwd = 2, col = \"blue\")\nlines(age_grid, pred_grid$leftRight_hat[pred_grid$income == income_levels[3]], lwd = 2, col = \"red\")\n\nlegend(\"topleft\",\n  legend = income_labels,\n       lwd = 2,\n       col = c(\"black\", \"blue\", \"red\"),\n       bty = \"n\")\n\n\n\n\n\n\n\n\nThe plot shows that the predicted leftRight values increase with age for all three income levels, but the slope is steeper for higher-income respondents. This visualization provides an alternative way to understand how the relationship between age and leftRight changes across different income levels, compared to the previous plot of marginal effects. Which visualization is more informative depends on the research question and the audience.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Context Matters: A Guide to Interaction Terms</span>"
    ]
  },
  {
    "objectID": "chapters/03-chapter-two.html#a-brief-digression-polynomial-regression",
    "href": "chapters/03-chapter-two.html#a-brief-digression-polynomial-regression",
    "title": "4  Context Matters: A Guide to Interaction Terms",
    "section": "4.3 A Brief Digression: Polynomial Regression",
    "text": "4.3 A Brief Digression: Polynomial Regression\nWe now extend the interaction idea to nonlinearity. In an interaction, the slope of one variable changes with another variable (x × z). With polynomial terms, the slope of a variable changes with its own level by including powers like x² and x³. Although both are multiplicative in form, polynomial terms are conventionally treated as predictor transformations (basis expansions), not as interaction terms. Using age as an example, our regression model with a cubic term would look like this: \\[\nleftRight_i = \\alpha + \\beta_1 age_i + \\beta_2 age_i^2 + \\beta_3 age_i^3 + \\epsilon_i\n\\tag{4.5}\\]\nThe partial derivative of Equation 4.5 with respect to age is: \\[\n\\frac{\\partial leftRight_i}{\\partial age_i} = \\beta_1 + 2 \\beta_2 age_i + 3 \\beta_3 age_i^2\n\\tag{4.6}\\]\nIn R, a polynomial regression can be estimated by either using the poly() function (or including the polynomial terms manually) as follows:\n\nsummary(\n  lm(leftRight ~ poly(age, degree = 3, raw = TRUE), data = data2)\n)\n\n\nCall:\nlm(formula = leftRight ~ poly(age, degree = 3, raw = TRUE), data = data2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.25298 -0.55461  0.01145  0.54104  2.61350 \n\nCoefficients:\n                                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                         3.510e+00  5.398e-01   6.502 1.25e-10 ***\npoly(age, degree = 3, raw = TRUE)1  1.861e-01  3.825e-02   4.865 1.33e-06 ***\npoly(age, degree = 3, raw = TRUE)2 -3.574e-03  8.315e-04  -4.298 1.89e-05 ***\npoly(age, degree = 3, raw = TRUE)3  2.323e-05  5.631e-06   4.126 4.00e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8007 on 996 degrees of freedom\nMultiple R-squared:  0.1354,    Adjusted R-squared:  0.1328 \nF-statistic:    52 on 3 and 996 DF,  p-value: &lt; 2.2e-16\n\n\nAnd the plot of the marginal effect of age on leftRight would look like this:\n\n# Fit the polynomial regression model with raw polynomials\nmodel_poly &lt;- lm(leftRight ~ age + I(age^2) + I(age^3), data = data2) \n\n# Extract coefficients and variance-covariance matrix\ncoefs &lt;- coef(model_poly)\nvcov_matrix &lt;- vcov(model_poly)\n\n# Create age sequence for prediction\nage_seq &lt;- seq(18, 80, length.out = 100)\n\n# Calculate marginal effect: β₁ + 2*β₂*age + 3*β₃*age²\neffect &lt;- coefs[2] + 2 * coefs[3] * age_seq + 3 * coefs[4] * age_seq^2\n\n# Delta method for standard error:\n# For f(β) = β₁ + 2*β₂*age + 3*β₃*age², gradient is [1, 2*age, 3*age²]\n# SE = sqrt(gradient' * Vcov * gradient)\nse &lt;- sqrt(vcov_matrix[2, 2] + \n           4 * age_seq^2 * vcov_matrix[3, 3] + \n           9 * age_seq^4 * vcov_matrix[4, 4] +\n           4 * age_seq * vcov_matrix[2, 3] +\n           6 * age_seq^2 * vcov_matrix[2, 4] +\n           12 * age_seq^3 * vcov_matrix[3, 4])\n\n# Calculate 95% confidence intervals\nci_lower &lt;- effect - 1.96 * se\nci_upper &lt;- effect + 1.96 * se\n\n# Create plot\nplot(age_seq, effect, \n     type = \"l\", \n     lwd = 2,\n     ylim = c(min(ci_lower), max(ci_upper)),\n     xlab = \"Age\",\n    ylab = \"Marginal Effect of Age on Left-Right Placement\",\n     main = \"Marginal Effect of Age\\n(with 95% Confidence Intervals)\")\n\n# Add confidence interval as shaded region\npolygon(c(age_seq, rev(age_seq)), \n        c(ci_upper, rev(ci_lower)),\n        col = rgb(0.8, 0.2, 0.2, 0.2),\n        border = NA)\n\n# Add reference line at y=0\nabline(h = 0, lty = 2, col = \"gray\", lwd = 1)\n\n# Re-plot the line on top\nlines(age_seq, effect, lwd = 2, col = \"red\")\n\n\n\n\n\n\n\n\nThe plot shows that the marginal effect of age on leftRight is positive but decreasing for younger respondents, becomes not statistically distinguishable from zero for respondents between mid-40s and mid-50s, and becomes positive and significant again for older respondents. This U-shaped pattern illustrates how polynomial regression can capture non-linear relationships between a predictor variable and a response variable. In this example, the relationship between age and leftRight follows a nonlinear pattern with changing slope that can be captured by including polynomial terms in the regression model.\nOf course, other functional forms could be considered to capture different types of non-linear relationships. But the main point is that this example illustrates how polynomial regression can capture non-linear relationships between a predictor variable and a response variable.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Context Matters: A Guide to Interaction Terms</span>"
    ]
  },
  {
    "objectID": "chapters/02-chapter-one.html#shares",
    "href": "chapters/02-chapter-one.html#shares",
    "title": "4  Categorical and Compositional Predictors: A Guide",
    "section": "4.3 Shares",
    "text": "4.3 Shares\nAnother case that is subject to the same problem of reference categories but is often underemphasized in the literature is the case of shares. For instance, researchers are often interested in the effect of the share of the population living in urban areas, the share of the agricultural or industrial workforce, the share of ethnic or religious groups, or the share of the population with a certain level of education on some outcome (to name but a few examples). In all these cases, the share variable is bounded between 0 and 1 and thus has an implicit complement (e.g., rural share = 1 − urban share). For instance, if I have a variable that measures the share of the population living in urban areas, then a value of 0 means everyone is in the complement category, and a value of 1 means no one is in the complement category. This means that the interpretation of the coefficients for share variables is subject to the same problems as before and depends on the number of categories and on which share(s) are omitted from the model.\nTo illustrate the problem, consider party shares in government. Suppose I observe the share of cabinet seats held by left, center, and right parties. Each share is between 0 and 1 and the three shares sum to 1. Because the shares sum to 1, these relationships are always interpreted as shifts in composition (increasing one share necessarily decreases at least one other share). I also observe social spending per capita which serves as the response variable.\nBecause the shares sum to 1, one share must be omitted when I include an intercept. If I omit the right share, the model can be written as:\n\\[\nSocialSpendingpc_i = \\alpha_0 + \\beta_1 left_i + \\beta_2 center_i + \\epsilon_i\n\\]\nHowever, there are a number of different ways to specify the model. Since I can no longer display the mean of the response variable by group (as I did above), I establish a baseline by estimating a model with all party groups and no intercept. After that, I can drop the right share which is the reference category in the first model to demonstrate how both models are connected.\n\nmodel_drop_right &lt;- lm(social_spend_pc ~ left + center, data = data_party_share)\nmodel_no_intercept &lt;- lm(social_spend_pc ~ left + center + right - 1, data = data_party_share)\n\nfmt_coef &lt;- function(cs, term) {\n  if (!term %in% rownames(cs)) {\n    return(\"—\")\n  }\n  sprintf(\"%.2f (%.2f)\", cs[term, 1], cs[term, 2])\n}\n\ncs_drop_right &lt;- coef(summary(model_drop_right))\ncs_no_intercept &lt;- coef(summary(model_no_intercept))\n\nterms &lt;- c(\"(Intercept)\", \"left\", \"center\", \"right\")\n\ntable_out &lt;- data.frame(\n  Term = terms,\n  `No_Intercept` = c(\n    \"—\",\n    fmt_coef(cs_no_intercept, \"left\"),\n    fmt_coef(cs_no_intercept, \"center\"),\n    fmt_coef(cs_no_intercept, \"right\")\n  ),\n  `No_Right` = c(\n    fmt_coef(cs_drop_right, \"(Intercept)\"),\n    fmt_coef(cs_drop_right, \"left\"),\n    fmt_coef(cs_drop_right, \"center\"),\n    \"ref\"\n  ),\n  stringsAsFactors = FALSE\n)\n\nknitr::kable(\n  table_out,\n  align = \"lcc\",\n  caption = \"Party-share regressions with different baselines\"\n)\n\n\nParty-share regressions with different baselines\n\n\nTerm\nNo_Intercept\nNo_Right\n\n\n\n\n(Intercept)\n—\n517.22 (120.67)\n\n\nleft\n6987.47 (114.32)\n6470.26 (199.61)\n\n\ncenter\n1460.77 (113.01)\n943.56 (194.27)\n\n\nright\n517.22 (120.67)\nref\n\n\n\n\n\nThe no-intercept model displays the expected level of social spending per capita if a given party held all cabinet seats (i.e., its share equals 1 and the other shares equal 0). For example, the coefficient for left of about 7000 means that if a government were composed entirely of left parties, I would expect social spending per capita to be almost 7000. Similarly, the coefficients for center and right show the expected spending levels under hypothetical all-center or all-right governments. This specification serves as a diagnostic baseline because it shows the direction and magnitude of each party share’s association with social spending.\nIn the second model with an intercept, the right shares variable is absorbed into the intercept, and each remaining coefficient becomes a contrast against the omitted share rather than a standalone predicted level. The coefficient for intercept is now the expected level of social spending per capita if a government were composed entirely of right parties (i.e., right share equals 1 and the other shares equal 0). The coefficients for left and center are now interpreted as the expected change in social spending per capita for a one-unit (i.e., 100 percentage point) increase in the left (center) share and a simultaneous one-unit decrease in the right share, holding the center (left) share variable constant. Thus, the relationship between the left share and social spending can be mathematically expressed as follows:\n\\[E(SocialSpendingpc \\mid left=1, center=0, right=0) = \\alpha_0 + \\beta_1\\]\nAdding the coefficient for the intercept and the coefficient for left in the second model reproduces the coefficient for left in the no-intercept model. This means that the expected level of social spending per capita if a government were composed entirely of left parties is the sum of the coefficient for intercept and the coefficient for left in the second model, which matches the coefficient for left in the no-intercept model. The same logic applies to the center share.\nThe example illustrates that models with share variables are subject to the same issues of reference categories as models with categorical predictors. The interpretation of the coefficients depends on which share(s) are omitted from the model, and the choice of reference category can change the substantive interpretation of the results.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Categorical and Compositional Predictors: A Guide</span>"
    ]
  },
  {
    "objectID": "chapters/02-chapter-one.html#predictor-variables-with-more-than-two-categories",
    "href": "chapters/02-chapter-one.html#predictor-variables-with-more-than-two-categories",
    "title": "4  Categorical and Compositional Predictors: A Guide",
    "section": "4.2 Predictor Variables with More than Two Categories",
    "text": "4.2 Predictor Variables with More than Two Categories\nThe logic becomes a bit more complex when I have more than two categories. For instance, suppose I have another categorical variable called party identification with four possible groups: Left, Center, Right, and Other. To illustrate the link between reference categories and group means, I display the average donation amount for each party identification group in the table below. In addition, I add a row for the average donation amount for the combined Right and Other group, which will help me to illustrate what changes when I omit multiple categories (instead of one category) in the regression model.\n\nmean_party &lt;- aggregate(donationAmount ~ party, data = data.frame(\n  party = party,\n  donationAmount = donationAmount\n), FUN = mean)\nmean_ro &lt;- mean(donationAmount[party %in% c(\"Right\", \"Other\")])\nmean_party &lt;- rbind(\n  mean_party,\n  data.frame(party = \"Right + Other\", donationAmount = mean_ro)\n)\ncolnames(mean_party) &lt;- c(\"Party\", \"Mean Donation Amount\")\nknitr::kable(mean_party, digits = 2)\n\n\n\n\nParty\nMean Donation Amount\n\n\n\n\nCenter\n115.45\n\n\nLeft\n140.90\n\n\nOther\n101.14\n\n\nRight\n124.15\n\n\nRight + Other\n117.80\n\n\n\n\n\nTo estimate the relationship of a respondent’s party identification and donationAmount in a linear regression model, I need to choose one of the categories as the reference category. To illustrate what happens when I omit more than one category, I specify one regression model with Other as the reference category and another regression model with Right and Other jointly omitted (a pooled reference category). Mathematically, the first model can be written as follows:\n\\[\ndonationAmount_i  = \\alpha_0 + \\beta_1 left_i + \\beta_2 center_i + \\beta_3 right_i + \\epsilon_i\n\\]\nWith Right and Other pooled into a single reference category, the second model becomes:\n\\[\ndonationAmount_i = \\alpha_0 + \\beta_1 left_i + \\beta_2 center_i + \\epsilon_i\n\\]\n\n# Leave out \"Other\" as the reference category\nmodel_other_ref &lt;- lm(donationAmount ~ left + center + right, data = data_party)\n\n# Leave out \"Right\" and \"Other\" as reference categories\nmodel_ro_ref &lt;- lm(donationAmount ~ left + center, data = data_party)\n\nfmt_coef &lt;- function(cs, term) {\n  if (!term %in% rownames(cs)) {\n    return(\"—\")\n  }\n  sprintf(\"%.2f (%.2f)\", cs[term, 1], cs[term, 2])\n}\n\ncs_other &lt;- coef(summary(model_other_ref))\ncs_ro_ref &lt;- coef(summary(model_ro_ref))\n\nterms &lt;- c(\"(Intercept)\", \"Left\", \"Center\", \"Right\", \"Other\")\n\ntable_out &lt;- data.frame(\n  Term = terms,\n  `Ref:Other` = c(\n    fmt_coef(cs_other, \"(Intercept)\"),\n    fmt_coef(cs_other, \"left\"),\n    fmt_coef(cs_other, \"center\"),\n    fmt_coef(cs_other, \"right\"),\n    \"ref\"\n  ),\n  `Ref:Right_Other` = c(\n    fmt_coef(cs_ro_ref, \"(Intercept)\"),\n    fmt_coef(cs_ro_ref, \"left\"),\n    fmt_coef(cs_ro_ref, \"center\"),\n    \"ref\",\n    \"ref\"\n  ),\n  stringsAsFactors = FALSE\n)\n\nknitr::kable(\n  table_out,\n  align = \"lcc\",\n  caption = \"Party effects with different reference categories\"\n)\n\n\nParty effects with different reference categories\n\n\nTerm\nRef.Other\nRef.Right_Other\n\n\n\n\n(Intercept)\n101.14 (3.32)\n117.80 (1.80)\n\n\nLeft\n39.77 (3.83)\n23.11 (2.65)\n\n\nCenter\n14.31 (3.75)\n-2.35 (2.54)\n\n\nRight\n23.02 (3.91)\nref\n\n\nOther\nref\nref\n\n\n\n\n\nThe first column of the table reports estimates with Other as the reference category, so the coefficients for Left, Center, and Right are each interpreted relative to Other. This means that the coefficient of the intercept is the average donation amount for respondents identifying as Other, and the coefficients for Left, Center, and Right show how much more (or less) respondents in these groups donate on average compared to respondents in Other. As shown before, the results can be easily cross-checked with the means table. While the coefficient for the intercept in the regression is equal to the mean donation amount for Other respondents in the means table, the coefficients for Left, Center, and Right have to be added to the intercept to get the mean donation amount for these groups, which matches the values in the means table as well. For example, the average donation amount for Left respondents in the first column can be deduced as follows: \\[E(donationAmount \\mid \\text{Left}) = \\alpha_0 + \\beta_1 \\]\nwhich is about 101.14 + 39.77 = 140.91 dollars, which matches roughly the average donation amount for Left respondents in the means table (aside from differences in rounding). The same logic can be applied to the coefficients for Center and Right.\nIn the second column, however, I change the specification by omitting Right as well, which means Right and Other are pooled into a single reference category. Thus, this is not merely releveling; it is a different model specification because it compares Left and Center to Right and Other. Coefficients therefore change meaning. While the interpretation is still straightforward as before, the estimand is different from the first model.\nMore precisely, the coefficient for the intercept in the second column is now the average donation amount for respondents identifying as Right or Other. This can be confirmed by comparing the coefficient of the intercept with the row for Right or Other in the means table. This also means that the coefficients for Left and Center are now interpreted as the difference in average donation amounts between respondents identifying as either Left or Center on one hand and respondents identifying as Right or Other on the other hand. And since the coefficient of the intercept increased by almost 17 dollars compared to the first column, the coefficients for Left and Center decreased accordingly. For instance, the coefficient for Center is now negative, which reflects the fact that the average donation amount for respondents identifying as Center is 2.35 dollars less than the average donation amount for respondents identifying as Right or Other as the means table shows.\nThe main takeaway is that with pure releveling, fitted values and model fit do not change; only coefficient labels and comparisons do. With pooling reference categories, you change the comparison group and therefore the estimand and the substantive conclusions that you can draw.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Categorical and Compositional Predictors: A Guide</span>"
    ]
  },
  {
    "objectID": "chapters/02-chapter-one.html#compositional-predictors",
    "href": "chapters/02-chapter-one.html#compositional-predictors",
    "title": "4  Categorical and Compositional Predictors: A Guide",
    "section": "4.3 Compositional Predictors",
    "text": "4.3 Compositional Predictors\nAnother case that faces the same reference category problem, yet is often underemphasized in the literature, is compositional predictors, where values are interpretable only relative to one another and are constrained to sum to a constant, typically 1 or 100%. For instance, researchers are often interested in the effect of the share of the population living in urban areas, the share of the agricultural or industrial workforce, the share of ethnic or religious groups, or the share of the population with a certain level of education on some outcome (to name but a few examples). In all these cases, the share variable is bounded between 0 and 1 and thus has an implicit complement (e.g., rural share = 1 − urban share). For instance, if I have a variable that measures the share of the population living in urban areas, then a value of 0 means everyone is in the complement category, and a value of 1 means no one is in the complement category. This means that the interpretation of the coefficients for share variables is subject to the same problems as before and depends on the number of categories and on which share(s) are omitted from the model.\nTo illustrate the problem, consider party shares in government. Suppose I observe the share of cabinet seats held by left, center, and right parties. Each share is between 0 and 1 and the three shares sum to 1. Because the shares sum to 1, these relationships are always interpreted as shifts in composition (increasing one share necessarily decreases at least one other share). I also observe social spending per capita which serves as the response variable.\nBecause the shares sum to 1, one share must be omitted when I include an intercept. If I omit the right share, the model can be written as:\n\\[\nSocialSpendingpc_i = \\alpha_0 + \\beta_1 left_i + \\beta_2 center_i + \\epsilon_i\n\\]\nHowever, there are a number of different ways to specify the model. Since I can no longer display the mean of the response variable by group (as I did above), I establish a baseline by estimating a model with all party groups and no intercept. After that, I can drop the right share which is the reference category in the first model to demonstrate how both models are connected.\n\nmodel_drop_right &lt;- lm(social_spend_pc ~ left + center, data = data_party_share)\nmodel_no_intercept &lt;- lm(social_spend_pc ~ left + center + right - 1, data = data_party_share)\n\nfmt_coef &lt;- function(cs, term) {\n  if (!term %in% rownames(cs)) {\n    return(\"—\")\n  }\n  sprintf(\"%.2f (%.2f)\", cs[term, 1], cs[term, 2])\n}\n\ncs_drop_right &lt;- coef(summary(model_drop_right))\ncs_no_intercept &lt;- coef(summary(model_no_intercept))\n\nterms &lt;- c(\"(Intercept)\", \"left\", \"center\", \"right\")\n\ntable_out &lt;- data.frame(\n  Term = terms,\n  `No_Intercept` = c(\n    \"—\",\n    fmt_coef(cs_no_intercept, \"left\"),\n    fmt_coef(cs_no_intercept, \"center\"),\n    fmt_coef(cs_no_intercept, \"right\")\n  ),\n  `No_Right` = c(\n    fmt_coef(cs_drop_right, \"(Intercept)\"),\n    fmt_coef(cs_drop_right, \"left\"),\n    fmt_coef(cs_drop_right, \"center\"),\n    \"ref\"\n  ),\n  stringsAsFactors = FALSE\n)\n\nknitr::kable(\n  table_out,\n  align = \"lcc\",\n  caption = \"Party-share regressions with different baselines\"\n)\n\n\nParty-share regressions with different baselines\n\n\nTerm\nNo_Intercept\nNo_Right\n\n\n\n\n(Intercept)\n—\n517.22 (120.67)\n\n\nleft\n6987.47 (114.32)\n6470.26 (199.61)\n\n\ncenter\n1460.77 (113.01)\n943.56 (194.27)\n\n\nright\n517.22 (120.67)\nref\n\n\n\n\n\nThe no-intercept model displays the expected level of social spending per capita if a given party held all cabinet seats (i.e., its share equals 1 and the other shares equal 0). For example, the coefficient for left of about 7000 means that if a government were composed entirely of left parties, I would expect social spending per capita to be almost 7000. Similarly, the coefficients for center and right show the expected spending levels under hypothetical all-center or all-right governments. This specification serves as a diagnostic baseline because it shows the direction and magnitude of each party share’s association with social spending.\nIn the second model with an intercept, the right shares variable is absorbed into the intercept, and each remaining coefficient becomes a contrast against the omitted share rather than a standalone predicted level. The coefficient for intercept is now the expected level of social spending per capita if a government were composed entirely of right parties (i.e., right share equals 1 and the other shares equal 0). The coefficients for left and center are now interpreted as the expected change in social spending per capita for a one-unit (i.e., 100 percentage point) increase in the left (center) share and a simultaneous one-unit decrease in the right share, holding the center (left) share variable constant. Thus, the relationship between the left share and social spending can be mathematically expressed as follows:\n\\[E(SocialSpendingpc \\mid left=1, center=0, right=0) = \\alpha_0 + \\beta_1\\]\nAdding the coefficient for the intercept and the coefficient for left in the second model reproduces the coefficient for left in the no-intercept model. This means that the expected level of social spending per capita if a government were composed entirely of left parties is the sum of the coefficient for intercept and the coefficient for left in the second model, which matches the coefficient for left in the no-intercept model. The same logic applies to the center share.\nThe example illustrates that models with share variables are subject to the same issues of reference categories as models with categorical predictors. The interpretation of the coefficients depends on which share(s) are omitted from the model, and the choice of reference category can change the substantive interpretation of the results.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Categorical and Compositional Predictors: A Guide</span>"
    ]
  },
  {
    "objectID": "chapters/03-chapter-two.html#interaction-terms-as-context",
    "href": "chapters/03-chapter-two.html#interaction-terms-as-context",
    "title": "4  Context Matters: A Guide to Interaction Terms",
    "section": "",
    "text": "“If You Are Not a Liberal at 25, You Have No Heart. If You Are Not a Conservative at 35 You Have No Brain”\n— Quote Investigator",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Context Matters: A Guide to Interaction Terms</span>"
    ]
  },
  {
    "objectID": "chapters/Categorical_Compositional.html",
    "href": "chapters/Categorical_Compositional.html",
    "title": "2  Categorical and Compositional Predictors: A Guide",
    "section": "",
    "text": "2.1 Binary Predictor Variables\nDisclaimer: All data used in this chapter is simulated and does not reflect real-world data. The purpose of this chapter is to illustrate the concept of categorical and compositional predictors in regression analysis, not to make any claims about the relationship between gender, party identification, and political donations or party shares and social spending.\nI already discussed how to interpret coefficients in a regression model. What I have not discussed is that the interpretation of a coefficient as the expected change in the response variable for a one-unit increase in the predictor variable (holding all other predictors constant) is most direct when a one-unit change is substantively meaningful. For binary and categorical predictors, coefficients are instead interpreted as differences between categories defined by the coding scheme. This has consequences for how we specify models and interpret results as I will show in the following.\nSuppose I study the relationship between gender and political donations. I have a binary variable gender coded 0 for men and 1 for women and donationAmount in US dollars. To understand how categorical variables work in regression analysis, I start by computing the average donation amount for men and women:\nmean_donation &lt;- aggregate(donationAmount ~ gender, data = data, FUN = mean)\nmean_donation$gender &lt;- c(\"Men\", \"Women\")\ncolnames(mean_donation) &lt;- c(\"Gender\", \"Mean Donation Amount\")\nknitr::kable(mean_donation, digits = 2)\n\n\n\n\nGender\nMean Donation Amount\n\n\n\n\nMen\n98.75\n\n\nWomen\n148.22\nAs the table shows, men donate on average 98.75 dollars, while women donate on average 148.22 dollars. With that in mind, I estimate a regression model with donationAmount as the response variable and gender as the predictor variable. Mathematically, the model can be written as follows:\n\\[donationAmount_i = \\alpha_0 + \\beta_1 gender_i + \\epsilon_i\\]\nIn R, I estimate the model using the lm() function:\nlm(donationAmount ~ factor(gender), data = data)\n\n\nCall:\nlm(formula = donationAmount ~ factor(gender), data = data)\n\nCoefficients:\n    (Intercept)  factor(gender)1  \n          98.75            49.46\nI start with the interpretation of the results before digging deeper. The coefficient for gender is about 50. In the case of a binary variable, the interpretation is straightforward: The coefficient compares the coded group (1) to the reference group (0). More precisely, the coefficient of about 50 for gender means that women donate on average 50 dollars more than men.\nComparing the regression output to the means table, I can highlight two points. First, the coefficient of the intercept is about 98.75, which is the average donation amount for men. Put differently, the intercept equals the mean of the reference category of men in this specification because, more generally, the intercept is the expected outcome when all predictors are zero and factors are at their baseline levels. This can be expressed mathematically:\n\\[E(donationAmount \\mid \\text{men}) = \\alpha_0\\]\nThis is why, when the model includes an intercept, one category must be omitted; otherwise the full set of dummies is perfectly collinear with the intercept (the dummy-variable trap). That means that if I included binary variables for both men and women in the model, the dummy variables would be perfectly collinear with the intercept and the model would not be estimable.\nSecond, the coefficient for gender is about 50, which is the difference in mean donation amounts between men and women. Thus, the coefficient for gender does not give us the average donation amount for women, but rather the difference in average donation amounts between women and men. In turn, this means that the mean donation amount of women is the sum of the coefficient of the intercept and the coefficient for gender:\n\\[E(donationAmount \\mid \\text{women}) = \\alpha_0 + \\beta_1\\]\nLastly, the substantive interpretation of the results does not change if I alter the reference category. With pure releveling (changing only which category is omitted), fitted values and model fit stay the same, but coefficient labels and interpretations change. To illustrate this, I can relevel the gender variable so that women are the reference category and are omitted from the model:\nlm(donationAmount ~ relevel(factor(gender), ref = \"1\"), data = data)\n\n\nCall:\nlm(formula = donationAmount ~ relevel(factor(gender), ref = \"1\"), \n    data = data)\n\nCoefficients:\n                        (Intercept)  relevel(factor(gender), ref = \"1\")0  \n                             148.22                               -49.46\nAs shown, the coefficient for intercept is now about 148, which is equal to the average donation amount for women according to the means table. The coefficient for gender (level 0) now displays the difference in donation amount of men compared to women. More precisely, it is now about -50, meaning that men donate on average 50 dollars less than women. Again, summing the coefficient of the intercept and the coefficient for gender gives the average donation amount for men. Thus, while the coefficients of intercept and gender have changed, the substantive interpretation of the results has not. The choice of reference category does not affect the substantive interpretation of the results, but it does affect how the coefficients are read.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Categorical and Compositional Predictors: A Guide</span>"
    ]
  },
  {
    "objectID": "chapters/Categorical_Compositional.html#predictor-variables-with-more-than-two-categories",
    "href": "chapters/Categorical_Compositional.html#predictor-variables-with-more-than-two-categories",
    "title": "2  Categorical and Compositional Predictors: A Guide",
    "section": "2.2 Predictor Variables with More than Two Categories",
    "text": "2.2 Predictor Variables with More than Two Categories\nThe logic becomes a bit more complex when I have more than two categories. For instance, suppose I have another categorical variable called party identification with four possible groups: Left, Center, Right, and Other. To illustrate the link between reference categories and group means, I display the average donation amount for each party identification group in the table below. In addition, I add a row for the average donation amount for the combined Right and Other group, which will help me to illustrate what changes when I omit multiple categories (instead of one category) in the regression model.\n\nmean_party &lt;- aggregate(donationAmount ~ party, data = data.frame(\n  party = party,\n  donationAmount = donationAmount\n), FUN = mean)\nmean_ro &lt;- mean(donationAmount[party %in% c(\"Right\", \"Other\")])\nmean_party &lt;- rbind(\n  mean_party,\n  data.frame(party = \"Right + Other\", donationAmount = mean_ro)\n)\ncolnames(mean_party) &lt;- c(\"Party\", \"Mean Donation Amount\")\nknitr::kable(mean_party, digits = 2)\n\n\n\n\nParty\nMean Donation Amount\n\n\n\n\nCenter\n115.45\n\n\nLeft\n140.90\n\n\nOther\n101.14\n\n\nRight\n124.15\n\n\nRight + Other\n117.80\n\n\n\n\n\nTo estimate the relationship of a respondent’s party identification and donationAmount in a linear regression model, I need to choose one of the categories as the reference category. To illustrate what happens when I omit more than one category, I specify one regression model with Other as the reference category and another regression model with Right and Other jointly omitted (a pooled reference category). Mathematically, the first model can be written as follows:\n\\[\ndonationAmount_i  = \\alpha_0 + \\beta_1 left_i + \\beta_2 center_i + \\beta_3 right_i + \\epsilon_i\n\\]\nWith Right and Other pooled into a single reference category, the second model becomes:\n\\[\ndonationAmount_i = \\alpha_0 + \\beta_1 left_i + \\beta_2 center_i + \\epsilon_i\n\\]\n\n# Leave out \"Other\" as the reference category\nmodel_other_ref &lt;- lm(donationAmount ~ left + center + right, data = data_party)\n\n# Leave out \"Right\" and \"Other\" as reference categories\nmodel_ro_ref &lt;- lm(donationAmount ~ left + center, data = data_party)\n\nfmt_coef &lt;- function(cs, term) {\n  if (!term %in% rownames(cs)) {\n    return(\"—\")\n  }\n  sprintf(\"%.2f (%.2f)\", cs[term, 1], cs[term, 2])\n}\n\ncs_other &lt;- coef(summary(model_other_ref))\ncs_ro_ref &lt;- coef(summary(model_ro_ref))\n\nterms &lt;- c(\"(Intercept)\", \"Left\", \"Center\", \"Right\", \"Other\")\n\ntable_out &lt;- data.frame(\n  Term = terms,\n  `Ref:Other` = c(\n    fmt_coef(cs_other, \"(Intercept)\"),\n    fmt_coef(cs_other, \"left\"),\n    fmt_coef(cs_other, \"center\"),\n    fmt_coef(cs_other, \"right\"),\n    \"ref\"\n  ),\n  `Ref:Right_Other` = c(\n    fmt_coef(cs_ro_ref, \"(Intercept)\"),\n    fmt_coef(cs_ro_ref, \"left\"),\n    fmt_coef(cs_ro_ref, \"center\"),\n    \"ref\",\n    \"ref\"\n  ),\n  stringsAsFactors = FALSE\n)\n\nknitr::kable(\n  table_out,\n  align = \"lcc\",\n  caption = \"Party effects with different reference categories\"\n)\n\n\nParty effects with different reference categories\n\n\nTerm\nRef.Other\nRef.Right_Other\n\n\n\n\n(Intercept)\n101.14 (3.32)\n117.80 (1.80)\n\n\nLeft\n39.77 (3.83)\n23.11 (2.65)\n\n\nCenter\n14.31 (3.75)\n-2.35 (2.54)\n\n\nRight\n23.02 (3.91)\nref\n\n\nOther\nref\nref\n\n\n\n\n\nThe first column of the table reports estimates with Other as the reference category, so the coefficients for Left, Center, and Right are each interpreted relative to Other. This means that the coefficient of the intercept is the average donation amount for respondents identifying as Other, and the coefficients for Left, Center, and Right show how much more (or less) respondents in these groups donate on average compared to respondents in Other. As shown before, the results can be easily cross-checked with the means table. While the coefficient for the intercept in the regression is equal to the mean donation amount for Other respondents in the means table, the coefficients for Left, Center, and Right have to be added to the intercept to get the mean donation amount for these groups, which matches the values in the means table as well. For example, the average donation amount for Left respondents in the first column can be deduced as follows: \\[E(donationAmount \\mid \\text{Left}) = \\alpha_0 + \\beta_1 \\]\nwhich is about 101.14 + 39.77 = 140.91 dollars, which matches roughly the average donation amount for Left respondents in the means table (aside from differences in rounding). The same logic can be applied to the coefficients for Center and Right.\nIn the second column, however, I change the specification by omitting Right as well, which means Right and Other are pooled into a single reference category. Thus, this is not merely releveling; it is a different model specification because it compares Left and Center to Right and Other. Coefficients therefore change meaning. While the interpretation is still straightforward as before, the estimand is different from the first model.\nMore precisely, the coefficient for the intercept in the second column is now the average donation amount for respondents identifying as Right or Other. This can be confirmed by comparing the coefficient of the intercept with the row for Right or Other in the means table. This also means that the coefficients for Left and Center are now interpreted as the difference in average donation amounts between respondents identifying as either Left or Center on one hand and respondents identifying as Right or Other on the other hand. And since the coefficient of the intercept increased by almost 17 dollars compared to the first column, the coefficients for Left and Center decreased accordingly. For instance, the coefficient for Center is now negative, which reflects the fact that the average donation amount for respondents identifying as Center is 2.35 dollars less than the average donation amount for respondents identifying as Right or Other as the means table shows.\nThe main takeaway is that with pure releveling, fitted values and model fit do not change; only coefficient labels and comparisons do. With pooling reference categories, you change the comparison group and therefore the estimand and the substantive conclusions that you can draw.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Categorical and Compositional Predictors: A Guide</span>"
    ]
  },
  {
    "objectID": "chapters/Categorical_Compositional.html#compositional-predictors",
    "href": "chapters/Categorical_Compositional.html#compositional-predictors",
    "title": "2  Categorical and Compositional Predictors: A Guide",
    "section": "2.3 Compositional Predictors",
    "text": "2.3 Compositional Predictors\nAnother case that faces the same reference category problem, yet is often underemphasized in the literature, is compositional predictors, where values are interpretable only relative to one another and are constrained to sum to a constant, typically 1 or 100%. For instance, researchers are often interested in the effect of the share of the population living in urban areas, the share of the agricultural or industrial workforce, the share of ethnic or religious groups, or the share of the population with a certain level of education on some outcome (to name but a few examples). In all these cases, the share variable is bounded between 0 and 1 and thus has an implicit complement (e.g., rural share = 1 − urban share). For instance, if I have a variable that measures the share of the population living in urban areas, then a value of 0 means everyone is in the complement category, and a value of 1 means no one is in the complement category. This means that the interpretation of the coefficients for share variables is subject to the same problems as before and depends on the number of categories and on which share(s) are omitted from the model.\nTo illustrate the problem, consider party shares in government. Suppose I observe the share of cabinet seats held by left, center, and right parties. Each share is between 0 and 1 and the three shares sum to 1. Because the shares sum to 1, these relationships are always interpreted as shifts in composition (increasing one share necessarily decreases at least one other share). I also observe social spending per capita which serves as the response variable.\nBecause the shares sum to 1, one share must be omitted when I include an intercept. If I omit the right share, the model can be written as:\n\\[\nSocialSpendingpc_i = \\alpha_0 + \\beta_1 left_i + \\beta_2 center_i + \\epsilon_i\n\\]\nHowever, there are a number of different ways to specify the model. Since I can no longer display the mean of the response variable by group (as I did above), I establish a baseline by estimating a model with all party groups and no intercept. After that, I can drop the right share which is the reference category in the first model to demonstrate how both models are connected.\n\nmodel_drop_right &lt;- lm(social_spend_pc ~ left + center, data = data_party_share)\nmodel_no_intercept &lt;- lm(social_spend_pc ~ left + center + right - 1, data = data_party_share)\n\nfmt_coef &lt;- function(cs, term) {\n  if (!term %in% rownames(cs)) {\n    return(\"—\")\n  }\n  sprintf(\"%.2f (%.2f)\", cs[term, 1], cs[term, 2])\n}\n\ncs_drop_right &lt;- coef(summary(model_drop_right))\ncs_no_intercept &lt;- coef(summary(model_no_intercept))\n\nterms &lt;- c(\"(Intercept)\", \"left\", \"center\", \"right\")\n\ntable_out &lt;- data.frame(\n  Term = terms,\n  `No_Intercept` = c(\n    \"—\",\n    fmt_coef(cs_no_intercept, \"left\"),\n    fmt_coef(cs_no_intercept, \"center\"),\n    fmt_coef(cs_no_intercept, \"right\")\n  ),\n  `No_Right` = c(\n    fmt_coef(cs_drop_right, \"(Intercept)\"),\n    fmt_coef(cs_drop_right, \"left\"),\n    fmt_coef(cs_drop_right, \"center\"),\n    \"ref\"\n  ),\n  stringsAsFactors = FALSE\n)\n\nknitr::kable(\n  table_out,\n  align = \"lcc\",\n  caption = \"Party-share regressions with different baselines\"\n)\n\n\nParty-share regressions with different baselines\n\n\nTerm\nNo_Intercept\nNo_Right\n\n\n\n\n(Intercept)\n—\n517.22 (120.67)\n\n\nleft\n6987.47 (114.32)\n6470.26 (199.61)\n\n\ncenter\n1460.77 (113.01)\n943.56 (194.27)\n\n\nright\n517.22 (120.67)\nref\n\n\n\n\n\nThe no-intercept model displays the expected level of social spending per capita if a given party held all cabinet seats (i.e., its share equals 1 and the other shares equal 0). For example, the coefficient for left of about 7000 means that if a government were composed entirely of left parties, I would expect social spending per capita to be almost 7000. Similarly, the coefficients for center and right show the expected spending levels under hypothetical all-center or all-right governments. This specification serves as a diagnostic baseline because it shows the direction and magnitude of each party share’s association with social spending.\nIn the second model with an intercept, the right shares variable is absorbed into the intercept, and each remaining coefficient becomes a contrast against the omitted share rather than a standalone predicted level. The coefficient for intercept is now the expected level of social spending per capita if a government were composed entirely of right parties (i.e., right share equals 1 and the other shares equal 0). The coefficients for left and center are now interpreted as the expected change in social spending per capita for a one-unit (i.e., 100 percentage point) increase in the left (center) share and a simultaneous one-unit decrease in the right share, holding the center (left) share variable constant. Thus, the relationship between the left share and social spending can be mathematically expressed as follows:\n\\[E(SocialSpendingpc \\mid left=1, center=0, right=0) = \\alpha_0 + \\beta_1\\]\nAdding the coefficient for the intercept and the coefficient for left in the second model reproduces the coefficient for left in the no-intercept model. This means that the expected level of social spending per capita if a government were composed entirely of left parties is the sum of the coefficient for intercept and the coefficient for left in the second model, which matches the coefficient for left in the no-intercept model. The same logic applies to the center share.\nThe example illustrates that models with share variables are subject to the same issues of reference categories as models with categorical predictors. The interpretation of the coefficients depends on which share(s) are omitted from the model, and the choice of reference category can change the substantive interpretation of the results.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Categorical and Compositional Predictors: A Guide</span>"
    ]
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "From Beta to Meaning: A Guide to Interpreting Regression Analysis",
    "section": "0.3 Prerequisites",
    "text": "0.3 Prerequisites\nYou do not need advanced mathematics to begin.\nRecommended background:\n\nhigh-school algebra,\nbasic comfort with graphs and percentages,\ncuriosity about data and uncertainty.\n\nHelpful but optional:\n\nprior exposure to R (for reading code snippets),\nbasic probability notation.\n\nMost chapters avoid heavy notation. When formulas appear, the focus is on interpretation rather than derivation.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>From Beta to Meaning</span>"
    ]
  },
  {
    "objectID": "index.html#disclaimer",
    "href": "index.html#disclaimer",
    "title": "From Beta to Meaning: A Guide to Interpreting Regression Analysis",
    "section": "0.4 Disclaimer",
    "text": "0.4 Disclaimer\nAll datasets are simulated. They are designed for learning and do not represent real individuals or institutions.\nCode snippets are included to illustrate ideas, not to provide production-ready software. The examples are written in R, but the conceptual lessons transfer to other languages and tools. You are encouraged to adapt, test, and extend the code for your own use cases.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>From Beta to Meaning</span>"
    ]
  },
  {
    "objectID": "index.html#how-to-read",
    "href": "index.html#how-to-read",
    "title": "From Beta to Meaning: A Guide to Interpreting Regression Analysis",
    "section": "0.4 How to read",
    "text": "0.4 How to read\nUse the navigation sidebar to move between chapters.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>So What? Interpreting Regression Analysis</span>"
    ]
  },
  {
    "objectID": "chapters/Interaction_Polynomials.html",
    "href": "chapters/Interaction_Polynomials.html",
    "title": "3  Context Matters: A Guide to Interaction Terms",
    "section": "",
    "text": "3.1 Interaction Terms as Context\nDisclaimer: All data used in this chapter is simulated and does not reflect real-world data. The purpose of this chapter is to illustrate the concept of interaction terms in linear regression models, not to make any claims about the relationship between age, income, and ideological placement.\nResearchers often want to know whether relationships differ across contexts. We use ideological self-placement as the running example. More specifically, I want to know whether age affects left-right self-placement. In addition, I assume that income affects ideological leanings as well, meaning that voters at the lower end of the income distribution are typically more left than voters on the higher end of the income distribution. So, how can interaction terms help us understand the relationship between age, income and ideological placement? Does the relationship between age and ideological placement differ across income levels? If so, how can we model this relationship?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Context Matters: A Guide to Interaction Terms</span>"
    ]
  },
  {
    "objectID": "chapters/Interaction_Polynomials.html#interaction-terms-as-context",
    "href": "chapters/Interaction_Polynomials.html#interaction-terms-as-context",
    "title": "3  Context Matters: A Guide to Interaction Terms",
    "section": "",
    "text": "“If You Are Not a Liberal at 25, You Have No Heart. If You Are Not a Conservative at 35 You Have No Brain”\n— Quote Investigator",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Context Matters: A Guide to Interaction Terms</span>"
    ]
  },
  {
    "objectID": "chapters/Interaction_Polynomials.html#what-is-an-interaction-term",
    "href": "chapters/Interaction_Polynomials.html#what-is-an-interaction-term",
    "title": "3  Context Matters: A Guide to Interaction Terms",
    "section": "3.2 What is an Interaction Term?",
    "text": "3.2 What is an Interaction Term?\nIn this example, income is measured in tens of thousands, and leftRight is a 0-10 self-placement scale where higher values indicate more right-leaning views.\nWe established in the previous chapter that a coefficient in a regression model represents the average effect of a predictor variable on the response variable, holding all other variables constant. However, this assumes that the effect of the predictor is the same across all contexts. Using a linear regression model with a continuous response variable leftRight and a predictor variable age, we can illustrate this point. Mathematically, our model without an interaction term looks as follows:\n\\[\nleftRight_i = \\alpha + \\beta_1 age_i + \\epsilon_i\n\\tag{3.1}\\]\nEquation 3.1 shows that the marginal effect of a predictor variable in a linear regression model is represented by the coefficient \\(\\beta_1\\). To understand interactions, it is helpful to know that the marginal effect of a predictor can be read directly from the equation because it is the partial derivative of the response variable with respect to the predictor variable. In our simple regression model, the marginal effect of age is \\(\\beta_1\\), which means that for every one-unit increase in age, the expected change in leftRight is \\(\\beta_1\\) units. Mathematically, the partial derivative of Equation 3.1 can be expressed as: \\[\n\\frac{\\partial leftRight_i}{\\partial age_i} = \\beta_1\n\\tag{3.2}\\]\nIn R, this model can be estimated using the lm() function as follows:\n\nsummary(\n  lm(leftRight ~ age, data = data)\n)\n\n\nCall:\nlm(formula = leftRight ~ age, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.5059 -0.8757 -0.0084  0.9727  3.0922 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 3.697214   0.118956   31.08   &lt;2e-16 ***\nage         0.045269   0.002289   19.78   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.289 on 998 degrees of freedom\nMultiple R-squared:  0.2816,    Adjusted R-squared:  0.2809 \nF-statistic: 391.3 on 1 and 998 DF,  p-value: &lt; 2.2e-16\n\n\nSo, why is this important to understand interaction terms? An interaction term is essentially a multiplicative combination of two predictor variables. When we include an interaction term in our regression model, we simply add two predictors and their product to the equation. Let’s assume that we want to know whether the effect of age on leftRight depends on the income of a respondent. Our regression model with the interaction term would look like this: \\[\nleftRight_i = \\alpha + \\beta_1 age_i + \\beta_2 income_i + \\beta_3 (age_i \\times income_i) + \\epsilon_i\n\\tag{3.3}\\]\nIf we take the partial derivative of Equation 3.3 with respect to age, we get: \\[\n\\frac{\\partial leftRight_i}{\\partial age_i} = \\beta_1 + \\beta_3 income_i\n\\tag{3.4}\\]\nAs Equation 3.4 shows, the effect of age on leftRight is no longer constant but depends on the value of income. The coefficient \\(\\beta_3\\) represents the change in the effect of age for each one-unit increase in income. If \\(\\beta_3\\) is positive, it means that the effect of age on leftRight increases as income increases. Conversely, if \\(\\beta_3\\) is negative, it means that the effect of age on leftRight decreases as income increases.\nIn R, this would look like this:\n\nsummary(\n  lm(leftRight ~ age * income, data = data)\n)\n\n\nCall:\nlm(formula = leftRight ~ age * income, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.45589 -0.55774  0.02019  0.56182  2.66821 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 2.4255133  0.2030559  11.945  &lt; 2e-16 ***\nage         0.0224525  0.0038078   5.896 5.08e-09 ***\nincome      0.1625065  0.0264208   6.151 1.12e-09 ***\nage:income  0.0037022  0.0005002   7.401 2.86e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8063 on 996 degrees of freedom\nMultiple R-squared:  0.7196,    Adjusted R-squared:  0.7187 \nF-statistic: 851.9 on 3 and 996 DF,  p-value: &lt; 2.2e-16\n\n\n(R adds the constitutive terms automatically when you use the * operator between two variables in the formula.)\nEven though it is more informative to plot the interaction to understand how the effect of age changes across different income levels, we can also look at the coefficients to get a sense of the interaction. First, we can see that the coefficient for age is positive. However, the coefficient for age gives us only the effect of age when income is zero, which is not a meaningful value in this context. A solution here would be to center the income variable around its mean before including it in the regression model. This way, the coefficient for age would represent the effect of age at the average income level.\nSecond, the coefficient for the interaction term age:income is positive, which indicates that the effect of age on leftRight increases as income increases. This means that age is more strongly associated with rightward placement among higher-income respondents than among lower-income respondents. Therefore, the table alone already gives us a pretty good idea of the interaction, but it is often more intuitive to visualize it:\n\n# Fit the model with interaction\nmodel &lt;- lm(leftRight ~ age * income, data = data)\n\n# Extract coefficients and variance-covariance matrix\ncoefs &lt;- coef(model)\nvcov_matrix &lt;- vcov(model)\n\nincome_seq &lt;- seq(2, 12, length.out = 100)\n\neffect &lt;- coefs[2] + coefs[4] * income_seq\n\nse &lt;- sqrt(vcov_matrix[2, 2] + \n           income_seq^2 * vcov_matrix[4, 4] + \n           2 * income_seq * vcov_matrix[2, 4])\n\nci_lower &lt;- effect - 1.96 * se\nci_upper &lt;- effect + 1.96 * se\n\n# Create plot\nplot(income_seq, effect, \n     type = \"l\", \n     lwd = 2,\n     ylim = c(min(ci_lower), max(ci_upper)),\n  xlab = \"Income (tens of thousands)\",\n  ylab = \"Effect of Age on Left-Right Placement\",\n  main = \"Marginal Effect of Age by Income\\n(with 95% Confidence Intervals)\")\n\n# Add confidence interval as shaded region\npolygon(c(income_seq, rev(income_seq)), \n        c(ci_upper, rev(ci_lower)),\n        col = rgb(0.2, 0.2, 0.8, 0.2),\n        border = NA)\n\n# Add reference line at y=0\nabline(h = 0, lty = 2, col = \"gray\", lwd = 1)\n\n# Re-plot the line on top\nlines(income_seq, effect, lwd = 2, col = \"blue\")\n\n\n\n\n\n\n\n\nTo plot the marginal effect of age on leftRight across different income levels, along with 95% confidence intervals, we use the coefficients and variance-covariance matrix from the fitted model. To compute variance for the confidence intervals, we apply the delta method:\n\\[Var(\\beta_1 + \\beta_3 \\cdot income) = Var(\\beta_1) + income^2 \\cdot Var(\\beta_3) + 2 \\cdot income \\cdot Cov(\\beta_1, \\beta_3)\\]\nThe plot shows that the estimated effect of age is positive across the observed income range. This visualization gives us a much clearer picture of how the effect of age changes across income levels compared to a regression table. While age increases rightward placement for all income levels, the effect is much stronger for higher-income respondents than for lower-income respondents.\nAn alternative way to visualize the interaction is to plot predicted values of leftRight across age for different income levels. To do so, we use the 10%, 50%, and 90% quantiles of the income variable to represent low, medium, and high income levels, respectively. We then plot the predicted leftRight values across age for these three income levels, along with confidence intervals.\n\nincome_levels &lt;- as.numeric(quantile(data$income, probs = c(0.1, 0.5, 0.9)))\nincome_labels &lt;- paste0(c(\"P10 = \", \"P50 = \", \"P90 = \"), sprintf(\"%.1f\", income_levels))\nage_grid &lt;- seq(18, 80, length.out = 100)\n\npred_grid &lt;- expand.grid(\n  age = age_grid,\n  income = income_levels\n)\n\npred_ci &lt;- predict(model, newdata = pred_grid, interval = \"confidence\")\npred_grid$leftRight_hat &lt;- pred_ci[, \"fit\"]\npred_grid$ci_lower &lt;- pred_ci[, \"lwr\"]\npred_grid$ci_upper &lt;- pred_ci[, \"upr\"]\n\nplot(age_grid, pred_grid$leftRight_hat[pred_grid$income == income_levels[1]],\n     type = \"l\",\n     lwd = 2,\n     ylim = range(pred_grid$ci_lower, pred_grid$ci_upper),\n     xlab = \"Age\",\n     ylab = \"Predicted Left-Right Placement\",\n    main = \"Predicted Left-Right by Age\\n(at Income P10, P50, and P90)\")\n\npolygon(c(age_grid, rev(age_grid)),\n        c(pred_grid$ci_upper[pred_grid$income == income_levels[1]],\n          rev(pred_grid$ci_lower[pred_grid$income == income_levels[1]])),\n        col = rgb(0, 0, 0, 0.15),\n        border = NA)\n\nlines(age_grid, pred_grid$leftRight_hat[pred_grid$income == income_levels[2]], lwd = 2, col = \"blue\")\nlines(age_grid, pred_grid$leftRight_hat[pred_grid$income == income_levels[3]], lwd = 2, col = \"red\")\n\npolygon(c(age_grid, rev(age_grid)),\n        c(pred_grid$ci_upper[pred_grid$income == income_levels[2]],\n          rev(pred_grid$ci_lower[pred_grid$income == income_levels[2]])),\n        col = rgb(0, 0, 1, 0.15),\n        border = NA)\n\npolygon(c(age_grid, rev(age_grid)),\n        c(pred_grid$ci_upper[pred_grid$income == income_levels[3]],\n          rev(pred_grid$ci_lower[pred_grid$income == income_levels[3]])),\n        col = rgb(1, 0, 0, 0.15),\n        border = NA)\n\nlines(age_grid, pred_grid$leftRight_hat[pred_grid$income == income_levels[1]], lwd = 2, col = \"black\")\nlines(age_grid, pred_grid$leftRight_hat[pred_grid$income == income_levels[2]], lwd = 2, col = \"blue\")\nlines(age_grid, pred_grid$leftRight_hat[pred_grid$income == income_levels[3]], lwd = 2, col = \"red\")\n\nlegend(\"topleft\",\n  legend = income_labels,\n       lwd = 2,\n       col = c(\"black\", \"blue\", \"red\"),\n       bty = \"n\")\n\n\n\n\n\n\n\n\nThe plot shows that the predicted leftRight values increase with age for all three income levels, but the slope is steeper for higher-income respondents. This visualization provides an alternative way to understand how the relationship between age and leftRight changes across different income levels, compared to the previous plot of marginal effects. Which visualization is more informative depends on the research question and the audience.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Context Matters: A Guide to Interaction Terms</span>"
    ]
  },
  {
    "objectID": "chapters/Interaction_Polynomials.html#a-brief-digression-polynomial-regression",
    "href": "chapters/Interaction_Polynomials.html#a-brief-digression-polynomial-regression",
    "title": "3  Context Matters: A Guide to Interaction Terms",
    "section": "3.3 A Brief Digression: Polynomial Regression",
    "text": "3.3 A Brief Digression: Polynomial Regression\nWe now extend the interaction idea to nonlinearity. In an interaction, the slope of one variable changes with another variable (x × z). With polynomial terms, the slope of a variable changes with its own level by including powers like x² and x³. Although both are multiplicative in form, polynomial terms are conventionally treated as predictor transformations (basis expansions), not as interaction terms. Using age as an example, our regression model with a cubic term would look like this: \\[\nleftRight_i = \\alpha + \\beta_1 age_i + \\beta_2 age_i^2 + \\beta_3 age_i^3 + \\epsilon_i\n\\tag{3.5}\\]\nThe partial derivative of Equation 3.5 with respect to age is: \\[\n\\frac{\\partial leftRight_i}{\\partial age_i} = \\beta_1 + 2 \\beta_2 age_i + 3 \\beta_3 age_i^2\n\\tag{3.6}\\]\nIn R, a polynomial regression can be estimated by either using the poly() function (or including the polynomial terms manually) as follows:\n\nsummary(\n  lm(leftRight ~ poly(age, degree = 3, raw = TRUE), data = data2)\n)\n\n\nCall:\nlm(formula = leftRight ~ poly(age, degree = 3, raw = TRUE), data = data2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.25298 -0.55461  0.01145  0.54104  2.61350 \n\nCoefficients:\n                                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                         3.510e+00  5.398e-01   6.502 1.25e-10 ***\npoly(age, degree = 3, raw = TRUE)1  1.861e-01  3.825e-02   4.865 1.33e-06 ***\npoly(age, degree = 3, raw = TRUE)2 -3.574e-03  8.315e-04  -4.298 1.89e-05 ***\npoly(age, degree = 3, raw = TRUE)3  2.323e-05  5.631e-06   4.126 4.00e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8007 on 996 degrees of freedom\nMultiple R-squared:  0.1354,    Adjusted R-squared:  0.1328 \nF-statistic:    52 on 3 and 996 DF,  p-value: &lt; 2.2e-16\n\n\nAnd the plot of the marginal effect of age on leftRight would look like this:\n\n# Fit the polynomial regression model with raw polynomials\nmodel_poly &lt;- lm(leftRight ~ age + I(age^2) + I(age^3), data = data2) \n\n# Extract coefficients and variance-covariance matrix\ncoefs &lt;- coef(model_poly)\nvcov_matrix &lt;- vcov(model_poly)\n\n# Create age sequence for prediction\nage_seq &lt;- seq(18, 80, length.out = 100)\n\n# Calculate marginal effect: β₁ + 2*β₂*age + 3*β₃*age²\neffect &lt;- coefs[2] + 2 * coefs[3] * age_seq + 3 * coefs[4] * age_seq^2\n\n# Delta method for standard error:\n# For f(β) = β₁ + 2*β₂*age + 3*β₃*age², gradient is [1, 2*age, 3*age²]\n# SE = sqrt(gradient' * Vcov * gradient)\nse &lt;- sqrt(vcov_matrix[2, 2] + \n           4 * age_seq^2 * vcov_matrix[3, 3] + \n           9 * age_seq^4 * vcov_matrix[4, 4] +\n           4 * age_seq * vcov_matrix[2, 3] +\n           6 * age_seq^2 * vcov_matrix[2, 4] +\n           12 * age_seq^3 * vcov_matrix[3, 4])\n\n# Calculate 95% confidence intervals\nci_lower &lt;- effect - 1.96 * se\nci_upper &lt;- effect + 1.96 * se\n\n# Create plot\nplot(age_seq, effect, \n     type = \"l\", \n     lwd = 2,\n     ylim = c(min(ci_lower), max(ci_upper)),\n     xlab = \"Age\",\n    ylab = \"Marginal Effect of Age on Left-Right Placement\",\n     main = \"Marginal Effect of Age\\n(with 95% Confidence Intervals)\")\n\n# Add confidence interval as shaded region\npolygon(c(age_seq, rev(age_seq)), \n        c(ci_upper, rev(ci_lower)),\n        col = rgb(0.8, 0.2, 0.2, 0.2),\n        border = NA)\n\n# Add reference line at y=0\nabline(h = 0, lty = 2, col = \"gray\", lwd = 1)\n\n# Re-plot the line on top\nlines(age_seq, effect, lwd = 2, col = \"red\")\n\n\n\n\n\n\n\n\nThe plot shows that the marginal effect of age on leftRight is positive but decreasing for younger respondents, becomes not statistically distinguishable from zero for respondents between mid-40s and mid-50s, and becomes positive and significant again for older respondents. This U-shaped pattern illustrates how polynomial regression can capture non-linear relationships between a predictor variable and a response variable. In this example, the relationship between age and leftRight follows a nonlinear pattern with changing slope that can be captured by including polynomial terms in the regression model.\nOf course, other functional forms could be considered to capture different types of non-linear relationships. But the main point is that this example illustrates how polynomial regression can capture non-linear relationships between a predictor variable and a response variable.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Context Matters: A Guide to Interaction Terms</span>"
    ]
  },
  {
    "objectID": "index.html#what-this-collection-is-and-is-not",
    "href": "index.html#what-this-collection-is-and-is-not",
    "title": "From Beta to Meaning: A Guide to Interpreting Regression Analysis",
    "section": "0.2 What this collection is (and is not)",
    "text": "0.2 What this collection is (and is not)\nThis is a practice-oriented companion to formal training in statistics.\nIt is:\n\nconcept-first,\nexample-driven,\nfocused on decision-making,\nexplicit about assumptions, limitations, and interpretation.\n\nIt is not:\n\na replacement for a full introductory statistics course,\na complete reference for every method,\na programming manual.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>From Beta to Meaning</span>"
    ]
  },
  {
    "objectID": "index.html#how-to-read-this-book",
    "href": "index.html#how-to-read-this-book",
    "title": "From Beta to Meaning: A Guide to Interpreting Regression Analysis",
    "section": "0.5 How to read this book",
    "text": "0.5 How to read this book\nEach article is self-contained, so you can read them in any order. To deepen your understanding, use this collection alongside a comprehensive textbook or a formal course that provides stronger theoretical foundations.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>From Beta to Meaning</span>"
    ]
  },
  {
    "objectID": "index.html#why-this-collection",
    "href": "index.html#why-this-collection",
    "title": "From Beta to Meaning: A Guide to Interpreting Regression Analysis",
    "section": "",
    "text": "framing the right question,\ntranslating that question into a defensible statistical strategy,\nchecking assumptions and model diagnostics,\nevaluating robustness and uncertainty, and\nexplaining results clearly to technical and non-technical audiences.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>From Beta to Meaning</span>"
    ]
  },
  {
    "objectID": "chapters/Comparing_Estimates.html",
    "href": "chapters/Comparing_Estimates.html",
    "title": "4  Comparing Estimates Correctly: Why ‘Significant’ vs ‘Not Significant’ Is Not a Difference",
    "section": "",
    "text": "4.1 Why This Chapter Exists\nDisclaimer: All data used in this chapter is simulated and does not reflect real-world data. The purpose of this chapter is to illustrate how to correctly compare estimates across groups, time periods, or contexts, not to make any claims about the real-world relationships used in the examples.\nResearchers routinely compare findings across subgroups, time periods, or model specifications. A pattern I have seen again and again goes like this:\nThat conclusion is wrong. Whether two estimates lie on different sides of an arbitrary threshold (like 0.05) is neither a necessary nor sufficient condition for concluding that they differ. In fact, two estimates that are significant at the 0.05 level can differ as two estimates that are not significant at the 0.05 level. The key question is whether the difference between the two estimates is statistically distinguishable from zero, not whether each estimate individually crosses a threshold. In other words, the estimand of interest is:\n\\[\n\\Delta = \\hat\\theta_1 - \\hat\\theta_2\n\\tag{4.1}\\]\nThroughout this chapter, I teach one core idea: your question is about \\(\\Delta\\), not about whether each estimate individually crosses 0.05.\nTo make this concrete, consider a simple simulation. Two researchers run experiments with the same true treatment effect, but one has a slightly larger sample. Their estimates and p-values can easily fall on different sides of 0.05, even though the underlying effect is identical.\nset.seed(2026)\n\n# Two experiments with the SAME true effect (0.3)\nn_A &lt;- 200\nn_B &lt;- 150\n\ny_A_treat &lt;- rnorm(n_A / 2, mean = 0.3, sd = 1)\ny_A_ctrl  &lt;- rnorm(n_A / 2, mean = 0,   sd = 1)\n\ny_B_treat &lt;- rnorm(n_B / 2, mean = 0.3, sd = 1)\ny_B_ctrl  &lt;- rnorm(n_B / 2, mean = 0,   sd = 1)\n\ntest_A &lt;- t.test(y_A_treat, y_A_ctrl)\ntest_B &lt;- t.test(y_B_treat, y_B_ctrl)\n\ncat(\"Study A: estimate =\", round(test_A$estimate[1] - test_A$estimate[2], 3),\n    \", p =\", round(test_A$p.value, 4), \"\\n\")\n\nStudy A: estimate = 0.08 , p = 0.5625 \n\ncat(\"Study B: estimate =\", round(test_B$estimate[1] - test_B$estimate[2], 3),\n    \", p =\", round(test_B$p.value, 4), \"\\n\")\n\nStudy B: estimate = 0.38 , p = 0.0136\nEven though both experiments draw from the same data-generating process with the same treatment effect, the p-values can easily end up on different sides of 0.05. Concluding that the effects “differ” would be a mistake of reasoning about thresholds rather than about the quantity of interest.\nThe rest of this chapter shows how to do it right, across three common scenarios: independent samples, time-period splits on the same units, and geographic subgroup comparisons.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comparing Estimates Correctly: Why 'Significant' vs 'Not Significant' Is Not a Difference</span>"
    ]
  },
  {
    "objectID": "chapters/Comparing_Estimates.html#why-this-chapter-exists",
    "href": "chapters/Comparing_Estimates.html#why-this-chapter-exists",
    "title": "4  Comparing Estimates Correctly: Why ‘Significant’ vs ‘Not Significant’ Is Not a Difference",
    "section": "",
    "text": "Study A finds a statistically significant treatment effect (\\(p &lt; .05\\)). Study B finds a non-significant effect (\\(p = .12\\)). Conclusion: “The effect differs between the two settings.”\n\n\n\n\n\n\n\n\n\n\n\n\n\nWrong vs Right\n\n\n\nWrong: Compare \\(p_1 &lt; .05\\) and \\(p_2 &gt; .05\\) and conclude the effects differ.\nRight: Test \\(H_0: \\theta_1 - \\theta_2 = 0\\) directly.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comparing Estimates Correctly: Why 'Significant' vs 'Not Significant' Is Not a Difference</span>"
    ]
  },
  {
    "objectID": "chapters/Comparing_Estimates.html#a-decision-tree-for-comparing-two-estimates",
    "href": "chapters/Comparing_Estimates.html#a-decision-tree-for-comparing-two-estimates",
    "title": "4  Comparing Estimates Correctly: Why ‘Significant’ vs ‘Not Significant’ Is Not a Difference",
    "section": "4.2 A Decision Tree for Comparing Two Estimates",
    "text": "4.2 A Decision Tree for Comparing Two Estimates\nBefore diving into specific cases, I provide a decision tree that structures the key choices. When comparing two estimates, three questions determine the appropriate method:\n1. Are the estimates independent?\nIf the two estimates come from entirely separate samples with no shared units, they are independent. If the same individuals, countries, or other units contribute to both estimates, the estimates are correlated and the comparison must account for the covariance.\n2. Is the model linear or nonlinear?\nIn linear models, differences in coefficients translate directly to differences in effects. In nonlinear models (logit, Poisson, etc.), coefficient differences do not map straightforwardly to differences in substantive quantities; in those cases, compare marginal effects or predicted probabilities instead.\n3. Is this a single comparison or one of many?\nIf I perform many subgroup, time, or place comparisons, I need to adjust for multiple testing to avoid false discoveries.\nFor the direct comparison of two estimates, two formulas are essential. When the estimates are independent:\n\\[\nSE(\\Delta) = \\sqrt{SE(\\hat\\theta_1)^2 + SE(\\hat\\theta_2)^2}\n\\tag{4.2}\\]\nWhen the estimates are not independent (e.g., same units in both groups), the covariance must be accounted for:\n\\[\nVar(\\Delta) = Var(\\hat\\theta_1) + Var(\\hat\\theta_2) - 2 \\, Cov(\\hat\\theta_1, \\hat\\theta_2)\n\\tag{4.3}\\]\nThe independence condition is crucial. If the same individuals or a subset of the same individuals appear in both groups, using Equation 4.2 when Equation 4.3 is required will produce incorrect standard errors, typically too large, making the test conservative but misleading (Altman & Bland, 2003).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comparing Estimates Correctly: Why 'Significant' vs 'Not Significant' Is Not a Difference</span>"
    ]
  },
  {
    "objectID": "chapters/Comparing_Estimates.html#why-ci-overlap-and-threshold-crossing-are-unreliable",
    "href": "chapters/Comparing_Estimates.html#why-ci-overlap-and-threshold-crossing-are-unreliable",
    "title": "4  Comparing Estimates Correctly: Why ‘Significant’ vs ‘Not Significant’ Is Not a Difference",
    "section": "4.3 Why CI Overlap and Threshold Crossing Are Unreliable",
    "text": "4.3 Why CI Overlap and Threshold Crossing Are Unreliable\nA related heuristic that researchers often use is: “The 95% confidence intervals overlap, so there is no significant difference.” This rule is not generally valid.\nFor two independent estimates with equal standard errors, non-overlapping 95% CIs actually correspond to a test at roughly the 0.6% level, not the 5% level. In other words, the “no overlap” rule is far too strict: it will miss many true differences. Conversely, modest overlap does not mean the difference is zero.\nThe following simulation illustrates this. I generate two independent estimates whose true difference is nonzero and show that the 95% CIs can overlap even when the direct test of \\(\\Delta\\) is significant.\n\nset.seed(42)\n\ntheta_1 &lt;- 0.50\ntheta_2 &lt;- 0.20\nse_1 &lt;- 0.12\nse_2 &lt;- 0.11\n\nhat_1 &lt;- rnorm(1, theta_1, se_1)\nhat_2 &lt;- rnorm(1, theta_2, se_2)\n\nci_1 &lt;- hat_1 + c(-1, 1) * 1.96 * se_1\nci_2 &lt;- hat_2 + c(-1, 1) * 1.96 * se_2\n\ndelta &lt;- hat_1 - hat_2\nse_delta &lt;- sqrt(se_1^2 + se_2^2)\nci_delta &lt;- delta + c(-1, 1) * 1.96 * se_delta\nz_delta &lt;- delta / se_delta\np_delta &lt;- 2 * pnorm(-abs(z_delta))\n\ncat(\"Estimate 1:\", round(hat_1, 3), \" 95% CI: [\", round(ci_1[1], 3), \",\", round(ci_1[2], 3), \"]\\n\")\n\nEstimate 1: 0.665  95% CI: [ 0.429 , 0.9 ]\n\ncat(\"Estimate 2:\", round(hat_2, 3), \" 95% CI: [\", round(ci_2[1], 3), \",\", round(ci_2[2], 3), \"]\\n\")\n\nEstimate 2: 0.138  95% CI: [ -0.078 , 0.353 ]\n\ncat(\"CIs overlap:\", ci_1[1] &lt; ci_2[2] & ci_2[1] &lt; ci_1[2], \"\\n\\n\")\n\nCIs overlap: FALSE \n\ncat(\"Difference:\", round(delta, 3), \" SE:\", round(se_delta, 3),\n    \" 95% CI: [\", round(ci_delta[1], 3), \",\", round(ci_delta[2], 3), \"]\\n\")\n\nDifference: 0.527  SE: 0.163  95% CI: [ 0.208 , 0.846 ]\n\ncat(\"z =\", round(z_delta, 3), \", p =\", round(p_delta, 4), \"\\n\")\n\nz = 3.235 , p = 0.0012 \n\n\nThe figure below shows both perspectives side by side: the individual CIs (which may overlap) and the direct CI for \\(\\Delta\\) (which is the correct basis for inference).\n\npar(mfrow = c(1, 2), mar = c(4, 4, 3, 1))\n\n# Left panel: individual CIs\nplot(1, hat_1, xlim = c(0.5, 2.5), ylim = range(c(ci_1, ci_2)) + c(-0.05, 0.05),\n     xaxt = \"n\", xlab = \"\", ylab = \"Estimate\",\n     main = \"Individual 95% CIs\", pch = 19, cex = 1.3)\nsegments(1, ci_1[1], 1, ci_1[2], lwd = 2)\npoints(2, hat_2, pch = 19, cex = 1.3, col = \"blue\")\nsegments(2, ci_2[1], 2, ci_2[2], lwd = 2, col = \"blue\")\naxis(1, at = c(1, 2), labels = c(expression(hat(theta)[1]), expression(hat(theta)[2])))\nabline(h = 0, lty = 2, col = \"gray\")\n\n# Shade overlap region\noverlap_lo &lt;- max(ci_1[1], ci_2[1])\noverlap_hi &lt;- min(ci_1[2], ci_2[2])\nif (overlap_lo &lt; overlap_hi) {\n  rect(0.5, overlap_lo, 2.5, overlap_hi,\n       col = rgb(1, 0.8, 0, 0.2), border = NA)\n  text(1.5, (overlap_lo + overlap_hi) / 2, \"overlap\", cex = 0.8, col = \"orange3\")\n}\n\n# Right panel: difference CI\nplot(1, delta, xlim = c(0.5, 1.5), ylim = range(ci_delta) + c(-0.05, 0.05),\n     xaxt = \"n\", xlab = \"\", ylab = \"Difference\",\n     main = expression(\"95% CI for \" * Delta), pch = 19, cex = 1.3, col = \"darkgreen\")\nsegments(1, ci_delta[1], 1, ci_delta[2], lwd = 2, col = \"darkgreen\")\naxis(1, at = 1, labels = expression(hat(theta)[1] - hat(theta)[2]))\nabline(h = 0, lty = 2, col = \"gray\")\n\npar(mfrow = c(1, 1))\n\n\n\n\n\n\n\nFigure 4.1: Left: Individual 95% CIs for each estimate. Right: Direct 95% CI for the difference. CI overlap does not imply the difference is zero.\n\n\n\n\n\nThe key lesson is that CI overlap is a heuristic, not a replacement for a direct test. For independent estimates with equal variance, one can use approximately 83–84% CIs to achieve a visual test that corresponds to the 5% level, but I recommend always computing the direct test of \\(\\Delta\\) instead of relying on visual rules.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comparing Estimates Correctly: Why 'Significant' vs 'Not Significant' Is Not a Difference</span>"
    ]
  },
  {
    "objectID": "chapters/Comparing_Estimates.html#case-i-independent-samples-two-separate-experiments",
    "href": "chapters/Comparing_Estimates.html#case-i-independent-samples-two-separate-experiments",
    "title": "4  Comparing Estimates Correctly: Why ‘Significant’ vs ‘Not Significant’ Is Not a Difference",
    "section": "4.4 Case I — Independent Samples: Two Separate Experiments",
    "text": "4.4 Case I — Independent Samples: Two Separate Experiments\nI now work through the first and simplest scenario: comparing treatment effects from two entirely separate experiments. Suppose two researchers each run a randomized experiment to evaluate whether a mobilization message increases voter turnout. Researcher A works with Sample A; Researcher B works with Sample B. The samples are completely independent.\n\n4.4.1 The Tempting but Wrong Analysis\nThe tempting approach is to run separate regressions and compare the p-values:\n\nmodel_A &lt;- lm(turnout ~ treat, data = data_A)\nmodel_B &lt;- lm(turnout ~ treat, data = data_B)\n\ncat(\"--- Sample A ---\\n\")\n\n--- Sample A ---\n\ncat(\"Effect:\", round(coef(model_A)[\"treat\"], 4),\n    \" SE:\", round(summary(model_A)$coefficients[\"treat\", \"Std. Error\"], 4),\n    \" p:\", round(summary(model_A)$coefficients[\"treat\", \"Pr(&gt;|t|)\"], 4), \"\\n\\n\")\n\nEffect: 0.1154  SE: 0.049  p: 0.0191 \n\ncat(\"--- Sample B ---\\n\")\n\n--- Sample B ---\n\ncat(\"Effect:\", round(coef(model_B)[\"treat\"], 4),\n    \" SE:\", round(summary(model_B)$coefficients[\"treat\", \"Std. Error\"], 4),\n    \" p:\", round(summary(model_B)$coefficients[\"treat\", \"Pr(&gt;|t|)\"], 4), \"\\n\")\n\nEffect: 0.0454  SE: 0.0526  p: 0.3885 \n\n\nLooking at these results separately, one might conclude that the treatment “works” in one sample but “does not work” in the other, and therefore that the effects differ. But that reasoning is about thresholds, not about \\(\\Delta\\).\n\n\n4.4.2 Correct Approach A: Direct z-Test on \\(\\Delta\\)\nSince the samples are independent, I can apply Equation 4.2 directly:\n\nbeta_A &lt;- coef(model_A)[\"treat\"]\nbeta_B &lt;- coef(model_B)[\"treat\"]\nse_A &lt;- summary(model_A)$coefficients[\"treat\", \"Std. Error\"]\nse_B &lt;- summary(model_B)$coefficients[\"treat\", \"Std. Error\"]\n\ndelta &lt;- beta_A - beta_B\nse_delta &lt;- sqrt(se_A^2 + se_B^2)\nz &lt;- delta / se_delta\np &lt;- 2 * pnorm(-abs(z))\n\ncat(\"Difference (A - B):\", round(delta, 4), \"\\n\")\n\nDifference (A - B): 0.07 \n\ncat(\"SE of difference:  \", round(se_delta, 4), \"\\n\")\n\nSE of difference:   0.0719 \n\ncat(\"95% CI:            [\", round(delta - 1.96 * se_delta, 4), \",\",\n                             round(delta + 1.96 * se_delta, 4), \"]\\n\")\n\n95% CI:            [ -0.0709 , 0.211 ]\n\ncat(\"z =\", round(z, 3), \", p =\", round(p, 4), \"\\n\")\n\nz = 0.974 , p = 0.3302 \n\n\n\n\n4.4.3 Correct Approach B: Pooled Model with Interaction Term\nThe pedagogically clearer and often more practical approach is to estimate a single pooled model with an interaction term:\n\\[\nY_i = \\alpha + \\beta \\, T_i + \\gamma \\, G_i + \\delta \\, (T_i \\times G_i) + \\varepsilon_i\n\\tag{4.4}\\]\nwhere \\(T_i\\) is the treatment indicator, \\(G_i\\) is a group indicator (0 = A, 1 = B), and \\(\\delta\\) is the coefficient of interest: it directly estimates the difference in treatment effects between the two groups. The treatment effect in group A is \\(\\beta\\), and the treatment effect in group B is \\(\\beta + \\delta\\).\n\nmodel_pooled &lt;- lm(turnout ~ treat * group, data = data_pooled)\nsummary(model_pooled)\n\n\nCall:\nlm(formula = turnout ~ treat * group, data = data_pooled)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.4709 -0.4278 -0.3554  0.5722  0.6445 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   0.35545    0.03378  10.522   &lt;2e-16 ***\ntreat         0.11545    0.04915   2.349   0.0191 *  \ngroupB        0.02690    0.05057   0.532   0.5949    \ntreat:groupB -0.07002    0.07190  -0.974   0.3304    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4907 on 746 degrees of freedom\nMultiple R-squared:  0.00835,   Adjusted R-squared:  0.004362 \nF-statistic: 2.094 on 3 and 746 DF,  p-value: 0.09964\n\n\nThe coefficient on treat:groupB is \\(\\hat\\delta\\), which is the estimated difference in treatment effects. Note that this coefficient and its p-value correspond closely to the direct z-test above. This is not a coincidence: when both subgroup models use the same specification, the interaction approach and the direct comparison yield identical results in OLS.\n\ncoefs_pooled &lt;- coef(model_pooled)\nse_pooled &lt;- summary(model_pooled)$coefficients[, \"Std. Error\"]\n\neffects &lt;- c(\n  coefs_pooled[\"treat\"],\n  coefs_pooled[\"treat\"] + coefs_pooled[\"treat:groupB\"],\n  coefs_pooled[\"treat:groupB\"]\n)\nses &lt;- c(\n  se_pooled[\"treat\"],\n  sqrt(se_pooled[\"treat\"]^2 + se_pooled[\"treat:groupB\"]^2 +\n       2 * vcov(model_pooled)[\"treat\", \"treat:groupB\"]),\n  se_pooled[\"treat:groupB\"]\n)\n\nlabels &lt;- c(\"Effect in A\", \"Effect in B\", \"Difference (A - B)\")\ncols &lt;- c(\"black\", \"blue\", \"darkgreen\")\n\nplot(effects, 3:1, xlim = range(c(effects - 1.96 * ses, effects + 1.96 * ses)),\n     yaxt = \"n\", ylab = \"\", xlab = \"Estimate\",\n     main = \"Treatment Effects and Their Difference\",\n     pch = 19, col = cols, cex = 1.3)\nsegments(effects - 1.96 * ses, 3:1, effects + 1.96 * ses, 3:1, lwd = 2, col = cols)\naxis(2, at = 3:1, labels = labels, las = 1)\nabline(v = 0, lty = 2, col = \"gray\")\n\n\n\n\n\n\n\nFigure 4.2: Coefficient plot showing the treatment effect in each group and their difference. The difference (delta) answers the correct question.\n\n\n\n\n\n\n\n4.4.4 Interpretation Template\nWhen reporting this type of comparison, I recommend the following structure:\n\n“We estimated the treatment effect separately in each group (Sample A: \\(\\hat\\beta_A\\); Sample B: \\(\\hat\\beta_B\\)). To test whether these effects differ, we estimated a pooled model with an interaction term between the treatment indicator and the group indicator. The estimated difference was \\(\\hat\\delta\\) [95% CI: …, p = …], indicating [no evidence of / evidence of] a differential treatment effect across samples.”",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comparing Estimates Correctly: Why 'Significant' vs 'Not Significant' Is Not a Difference</span>"
    ]
  },
  {
    "objectID": "chapters/Comparing_Estimates.html#case-ii-non-independent-estimates-same-units-split-over-time",
    "href": "chapters/Comparing_Estimates.html#case-ii-non-independent-estimates-same-units-split-over-time",
    "title": "4  Comparing Estimates Correctly: Why ‘Significant’ vs ‘Not Significant’ Is Not a Difference",
    "section": "4.5 Case II — Non-Independent Estimates: Same Units Split over Time",
    "text": "4.5 Case II — Non-Independent Estimates: Same Units Split over Time\nThe second scenario is more subtle and more commonly mishandled. Suppose I have a panel dataset of countries observed over several decades, and I want to know whether the effect of a policy variable \\(X\\) on an outcome \\(Y\\) changed between two time periods (e.g., 1980–1999 vs 2000–2020). Because the same countries appear in both periods, the estimates are correlated. Applying the independent-samples formula (Equation 4.2) would be incorrect; I must use Equation 4.3 instead.\n\n4.5.1 The Tempting but Wrong Analysis: Split and Compare\nThe tempting approach is to split the data by period and run separate regressions:\n\npanel_early &lt;- panel[panel$post == 0, ]\npanel_late  &lt;- panel[panel$post == 1, ]\n\nmodel_early &lt;- lm(y ~ x + factor(country), data = panel_early)\nmodel_late  &lt;- lm(y ~ x + factor(country), data = panel_late)\n\ncat(\"--- 1980-1999 ---\\n\")\n\n--- 1980-1999 ---\n\ncat(\"Effect of X:\", round(coef(model_early)[\"x\"], 4),\n    \" SE:\", round(summary(model_early)$coefficients[\"x\", \"Std. Error\"], 4),\n    \" p:\", round(summary(model_early)$coefficients[\"x\", \"Pr(&gt;|t|)\"], 4), \"\\n\\n\")\n\nEffect of X: 0.5022  SE: 0.0554  p: 0 \n\ncat(\"--- 2000-2020 ---\\n\")\n\n--- 2000-2020 ---\n\ncat(\"Effect of X:\", round(coef(model_late)[\"x\"], 4),\n    \" SE:\", round(summary(model_late)$coefficients[\"x\", \"Std. Error\"], 4),\n    \" p:\", round(summary(model_late)$coefficients[\"x\", \"Pr(&gt;|t|)\"], 4), \"\\n\")\n\nEffect of X: 0.9102  SE: 0.0505  p: 0 \n\n\nComparing p-values from these two regressions tells us nothing about whether the effects differ. The correct approach is to estimate the difference directly, accounting for the correlation between periods.\n\n\n4.5.2 The Correct Approach: Pooled Interaction Model\nI estimate a single model on the full panel, including a period indicator and its interaction with \\(X\\):\n\\[\nY_{it} = \\alpha_i + \\tau_t + \\beta \\, X_{it} + \\delta \\, (X_{it} \\times Post_t) + \\varepsilon_{it}\n\\tag{4.5}\\]\nHere \\(\\alpha_i\\) are country fixed effects, \\(\\tau_t\\) captures time trends, \\(\\beta\\) is the effect of \\(X\\) in the early period, and \\(\\delta\\) is the change in the effect between periods, which is the quantity of interest.\n\nmodel_panel &lt;- lm(y ~ x * post + factor(country) + factor(year), data = panel)\n\ncoefs &lt;- summary(model_panel)$coefficients\ncat(\"Effect in 1980-1999 (beta):   \", round(coefs[\"x\", \"Estimate\"], 4),\n    \" SE:\", round(coefs[\"x\", \"Std. Error\"], 4), \"\\n\")\n\nEffect in 1980-1999 (beta):    0.5031  SE: 0.0542 \n\ncat(\"Change after 2000 (delta):    \", round(coefs[\"x:post\", \"Estimate\"], 4),\n    \" SE:\", round(coefs[\"x:post\", \"Std. Error\"], 4),\n    \" p:\", round(coefs[\"x:post\", \"Pr(&gt;|t|)\"], 4), \"\\n\")\n\nChange after 2000 (delta):     0.3979  SE: 0.0748  p: 0 \n\ncat(\"Effect in 2000-2020 (beta+delta):\", round(coefs[\"x\", \"Estimate\"] + coefs[\"x:post\", \"Estimate\"], 4), \"\\n\")\n\nEffect in 2000-2020 (beta+delta): 0.901 \n\n\nThe coefficient x:post (\\(\\hat\\delta\\)) directly tests whether the effect of \\(X\\) changed between the two periods, properly accounting for the fact that the same countries appear in both periods. The country fixed effects absorb country-level confounders, and year fixed effects absorb common time trends.\n\n\n\n\n\n\nOn Clustering Standard Errors\n\n\n\nIn panel settings, the error terms \\(\\varepsilon_{it}\\) are typically correlated within countries over time. For robust inference, cluster standard errors at the panel-unit level (here: country). In designs where there is also cross-sectional dependence, two-way clustering (by country and by year) may be appropriate. I use the sandwich and lmtest packages when clustering is needed:\n\nlibrary(sandwich)\nlibrary(lmtest)\ncoeftest(model_panel, vcov = vcovCL(model_panel, cluster = panel$country))\n\n\n\n\n\n4.5.3 Robustness: Alternative Break Years\nWhen the break year (here: 2000) is chosen by the researcher, it is good practice to show that results are not sensitive to this choice. I re-estimate the model using alternative break years and plot how \\(\\hat\\delta\\) varies:\n\nbreak_years &lt;- 1990:2010\ndeltas &lt;- numeric(length(break_years))\nses &lt;- numeric(length(break_years))\n\nfor (i in seq_along(break_years)) {\n  panel$post_alt &lt;- as.integer(panel$year &gt;= break_years[i])\n  m &lt;- lm(y ~ x * post_alt + factor(country), data = panel)\n  cs &lt;- summary(m)$coefficients\n  if (\"x:post_alt\" %in% rownames(cs)) {\n    deltas[i] &lt;- cs[\"x:post_alt\", \"Estimate\"]\n    ses[i] &lt;- cs[\"x:post_alt\", \"Std. Error\"]\n  }\n}\n\nplot(break_years, deltas, type = \"l\", lwd = 2,\n     ylim = range(c(deltas - 1.96 * ses, deltas + 1.96 * ses)),\n     xlab = \"Break Year\", ylab = expression(hat(delta)),\n     main = \"Sensitivity of Effect Change to Break Year\")\npolygon(c(break_years, rev(break_years)),\n        c(deltas + 1.96 * ses, rev(deltas - 1.96 * ses)),\n        col = rgb(0.2, 0.2, 0.8, 0.2), border = NA)\nlines(break_years, deltas, lwd = 2, col = \"blue\")\nabline(h = 0, lty = 2, col = \"gray\")\nabline(v = 2000, lty = 3, col = \"red\")\ntext(2000, max(deltas + 1.96 * ses) * 0.9, \"chosen break\", col = \"red\", cex = 0.8, pos = 4)\n\n\n\n\n\n\n\nFigure 4.3: Estimated change in the effect of X (delta) for different break years. The shaded region shows the 95% CI.\n\n\n\n\n\n\n\n\n\n\n\nStructural Break Tests\n\n\n\nFor designs where the break date is part of the hypothesis (rather than imposed by the researcher), formal structural break tests exist. The Chow test evaluates a known break date; the supremum Wald test (Andrews, 1993; Bai & Perron, 1998) can detect unknown break dates. These are available in the strucchange package in R.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comparing Estimates Correctly: Why 'Significant' vs 'Not Significant' Is Not a Difference</span>"
    ]
  },
  {
    "objectID": "chapters/Comparing_Estimates.html#case-iii-non-independent-estimates-geographic-split",
    "href": "chapters/Comparing_Estimates.html#case-iii-non-independent-estimates-geographic-split",
    "title": "4  Comparing Estimates Correctly: Why ‘Significant’ vs ‘Not Significant’ Is Not a Difference",
    "section": "4.6 Case III — Non-Independent Estimates: Geographic Split",
    "text": "4.6 Case III — Non-Independent Estimates: Geographic Split\nThe third scenario involves comparing estimates across geographic subgroups. Suppose I want to know whether the effect of social spending on inequality is different in Northern vs Southern European countries. The same logic applies: I should not run separate regressions and compare p-values. Instead, I estimate a single model with a region indicator and its interaction with the predictor of interest.\n\n4.6.1 Simple Pooled Interaction Model\nI estimate a model that includes the region indicator and its interaction with social spending:\n\ngeo_data$south &lt;- as.integer(geo_data$region == \"South\")\n\nmodel_geo &lt;- lm(inequality ~ spend * south + factor(country), data = geo_data)\n\ncs_geo &lt;- summary(model_geo)$coefficients\ncat(\"Effect in North (beta):       \", round(cs_geo[\"spend\", \"Estimate\"], 4),\n    \" SE:\", round(cs_geo[\"spend\", \"Std. Error\"], 4), \"\\n\")\n\nEffect in North (beta):        -0.8552  SE: 0.0653 \n\ncat(\"Difference South - North (delta):\", round(cs_geo[\"spend:south\", \"Estimate\"], 4),\n    \" SE:\", round(cs_geo[\"spend:south\", \"Std. Error\"], 4),\n    \" p:\", round(cs_geo[\"spend:south\", \"Pr(&gt;|t|)\"], 4), \"\\n\")\n\nDifference South - North (delta): 0.6453  SE: 0.0971  p: 0 \n\ncat(\"Effect in South (beta+delta): \", round(cs_geo[\"spend\", \"Estimate\"] + cs_geo[\"spend:south\", \"Estimate\"], 4), \"\\n\")\n\nEffect in South (beta+delta):  -0.2099 \n\n\nThe coefficient on spend:south directly tests whether the relationship between social spending and inequality differs across regions.\n\n\n4.6.2 Grouped Coefficient Plot\n\neff_north &lt;- cs_geo[\"spend\", \"Estimate\"]\neff_south &lt;- cs_geo[\"spend\", \"Estimate\"] + cs_geo[\"spend:south\", \"Estimate\"]\neff_diff  &lt;- cs_geo[\"spend:south\", \"Estimate\"]\n\nse_north &lt;- cs_geo[\"spend\", \"Std. Error\"]\nse_south &lt;- sqrt(cs_geo[\"spend\", \"Std. Error\"]^2 + cs_geo[\"spend:south\", \"Std. Error\"]^2 +\n                 2 * vcov(model_geo)[\"spend\", \"spend:south\"])\nse_diff  &lt;- cs_geo[\"spend:south\", \"Std. Error\"]\n\neffects &lt;- c(eff_north, eff_south, eff_diff)\nses &lt;- c(se_north, se_south, se_diff)\nlabels &lt;- c(\"North\", \"South\", \"Difference\\n(South - North)\")\ncols &lt;- c(\"steelblue\", \"firebrick\", \"darkgreen\")\n\nplot(effects, 3:1, xlim = range(c(effects - 1.96 * ses, effects + 1.96 * ses)),\n     yaxt = \"n\", ylab = \"\", xlab = \"Estimate\",\n     main = \"Effect of Social Spending on Inequality\",\n     pch = 19, col = cols, cex = 1.3)\nsegments(effects - 1.96 * ses, 3:1, effects + 1.96 * ses, 3:1, lwd = 2, col = cols)\naxis(2, at = 3:1, labels = labels, las = 1)\nabline(v = 0, lty = 2, col = \"gray\")\n\n\n\n\n\n\n\nFigure 4.4: Effect of social spending on inequality by region, with the estimated difference.\n\n\n\n\n\n\n\n4.6.3 Summary Table\n\nresults_geo &lt;- data.frame(\n  Group = c(\"North\", \"South\", \"Difference (South - North)\"),\n  Estimate = round(effects, 3),\n  SE = round(ses, 3),\n  CI_lower = round(effects - 1.96 * ses, 3),\n  CI_upper = round(effects + 1.96 * ses, 3)\n)\nknitr::kable(results_geo, row.names = FALSE,\n             col.names = c(\"Group\", \"Estimate\", \"SE\", \"95% CI Lower\", \"95% CI Upper\"),\n             caption = \"Effect of social spending on inequality by region\")\n\n\nEffect of social spending on inequality by region\n\n\n\n\n\n\n\n\n\nGroup\nEstimate\nSE\n95% CI Lower\n95% CI Upper\n\n\n\n\nNorth\n-0.855\n0.065\n-0.983\n-0.727\n\n\nSouth\n-0.210\n0.072\n-0.351\n-0.069\n\n\nDifference (South - North)\n0.645\n0.097\n0.455\n0.836\n\n\n\n\n\n\n\n4.6.4 Extension: Hierarchical Models\nFor richer heterogeneity across many countries or regions, a hierarchical (multilevel) model with random slopes can be useful. Instead of a single North/South split, I let the effect of spending vary by country:\n\\[\nY_{it} = \\alpha_i + (\\beta + u_i) \\, X_{it} + \\varepsilon_{it}\n\\]\nwhere \\(u_i \\sim N(0, \\sigma_u^2)\\) captures country-specific deviations from the average effect. This approach allows me to see the full distribution of effects rather than collapsing everything into two groups:\n\nlibrary(lme4)\n\nmodel_hier &lt;- lmer(inequality ~ spend + (spend | country), data = geo_data)\n\n# Extract country-level random slopes\nranefs &lt;- ranef(model_hier)$country\nfixef_spend &lt;- fixef(model_hier)[\"spend\"]\ncountry_effects &lt;- fixef_spend + ranefs$spend\n\ncat(\"Average effect:\", round(fixef_spend, 3), \"\\n\")\n\nAverage effect: -0.559 \n\ncat(\"SD of country effects:\", round(sd(country_effects), 3), \"\\n\")\n\nSD of country effects: 0.246 \n\ncat(\"Range:\", round(min(country_effects), 3), \"to\", round(max(country_effects), 3), \"\\n\")\n\nRange: -1.015 to -0.204 \n\n\nThe hierarchical approach is especially useful when the number of groups is too large for a simple factor interaction, or when I want to partially pool estimates toward a common mean to stabilize noisy group-level estimates.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comparing Estimates Correctly: Why 'Significant' vs 'Not Significant' Is Not a Difference</span>"
    ]
  },
  {
    "objectID": "chapters/Comparing_Estimates.html#practical-pitfalls-and-reviewer-proof-reporting",
    "href": "chapters/Comparing_Estimates.html#practical-pitfalls-and-reviewer-proof-reporting",
    "title": "4  Comparing Estimates Correctly: Why ‘Significant’ vs ‘Not Significant’ Is Not a Difference",
    "section": "4.7 Practical Pitfalls and Reviewer-Proof Reporting",
    "text": "4.7 Practical Pitfalls and Reviewer-Proof Reporting\nHaving covered the three main cases, I now summarize common pitfalls that can undermine comparisons even when the correct method is used.\nLow power of interaction tests. Interaction tests are often underpowered. Even when subgroup p-values look very different (e.g., \\(p = .01\\) vs \\(p = .20\\)), the interaction itself may not be significant because detecting a difference requires more statistical power than detecting a main effect. This is not a flaw of the method; it reflects the genuine uncertainty about whether the effects truly differ. Do not interpret a non-significant interaction as evidence that the effects are the same.\nMultiple subgroup comparisons without correction. If I compare effects across five regions, ten time periods, or many subgroups, the probability of finding at least one “significant” difference by chance increases rapidly. Adjust for multiple comparisons using methods like Bonferroni, Holm, or Benjamini-Hochberg, or use a joint test (e.g., an F-test of all interaction terms simultaneously).\nPost-hoc subgrouping. If subgroups are defined after inspecting the data (e.g., “the effect is strongest in countries with GDP above the median”), the resulting p-values are invalid. Pre-register subgroup comparisons or treat them as exploratory.\nNonlinear models. In logistic regression, Poisson regression, and other nonlinear models, comparing coefficients across groups is more complex because the coefficients are not on a natural scale. Compare substantive quantities instead: marginal effects, predicted probabilities, or risk ratios. In logit models specifically, coefficient differences can arise from differences in residual variance rather than true effect heterogeneity (Allison, 1999).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comparing Estimates Correctly: Why 'Significant' vs 'Not Significant' Is Not a Difference</span>"
    ]
  },
  {
    "objectID": "chapters/Comparing_Estimates.html#reporting-template",
    "href": "chapters/Comparing_Estimates.html#reporting-template",
    "title": "4  Comparing Estimates Correctly: Why ‘Significant’ vs ‘Not Significant’ Is Not a Difference",
    "section": "4.8 Reporting Template",
    "text": "4.8 Reporting Template\nWhen reporting a comparison of estimates, I recommend including the following elements:\n\n\n\n\n\n\nTemplate for Methods / Results Sections\n\n\n\nMethods: “We tested whether the effect of [predictor] on [outcome] differed across [groups / periods / contexts] by estimating a pooled model with an interaction term between [predictor] and [group indicator]. [If panel data: We included unit fixed effects and clustered standard errors at the unit level.]”\nResults: “The estimated effect was \\(\\hat\\theta_1 = ...\\) [95% CI: …] in [Group 1] and \\(\\hat\\theta_2 = ...\\) [95% CI: …] in [Group 2]. The estimated difference was \\(\\hat\\Delta = ...\\) [95% CI: …, \\(p = ...\\)], indicating [no statistically significant difference / a significant difference] in the effect across groups.”\nAlways report:\n\n\\(\\hat\\theta_1\\), \\(\\hat\\theta_2\\) (the group-specific estimates)\n\\(\\hat\\Delta\\), \\(SE(\\hat\\Delta)\\), 95% CI, p-value (the comparison)\nModel specification and dependence handling (clustering, pooled interaction, covariance estimation)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comparing Estimates Correctly: Why 'Significant' vs 'Not Significant' Is Not a Difference</span>"
    ]
  },
  {
    "objectID": "chapters/Comparing_Estimates.html#appendix-a-minimal-r-workflow",
    "href": "chapters/Comparing_Estimates.html#appendix-a-minimal-r-workflow",
    "title": "4  Comparing Estimates Correctly: Why ‘Significant’ vs ‘Not Significant’ Is Not a Difference",
    "section": "4.9 Appendix A — Minimal R Workflow",
    "text": "4.9 Appendix A — Minimal R Workflow\nThis appendix collects compact code recipes for each comparison scenario.\n\n4.9.1 Independent-Estimate z-Test\n\n# Given two independent estimates and their SEs\nbeta_1 &lt;- coef(model_1)[\"x\"]\nbeta_2 &lt;- coef(model_2)[\"x\"]\nse_1 &lt;- summary(model_1)$coefficients[\"x\", \"Std. Error\"]\nse_2 &lt;- summary(model_2)$coefficients[\"x\", \"Std. Error\"]\n\ndelta &lt;- beta_1 - beta_2\nse_delta &lt;- sqrt(se_1^2 + se_2^2)\nz &lt;- delta / se_delta\np &lt;- 2 * pnorm(-abs(z))\nci &lt;- delta + c(-1, 1) * qnorm(0.975) * se_delta\n\n\n\n4.9.2 Pooled Interaction Model\n\n# Stack data from two groups\ndata_pooled &lt;- rbind(\n  transform(data_1, group = 0),\n  transform(data_2, group = 1)\n)\n\nmodel &lt;- lm(y ~ x * group, data = data_pooled)\nsummary(model)  # coefficient on x:group is delta\n\n\n\n4.9.3 Panel Interaction with Clustered SE\n\nlibrary(sandwich)\nlibrary(lmtest)\n\nmodel_panel &lt;- lm(y ~ x * post + factor(unit) + factor(time), data = panel)\ncoeftest(model_panel, vcov = vcovCL(model_panel, cluster = panel$unit))\n\n\n\n4.9.4 Bootstrap Alternative for Complex Dependence\n\nlibrary(boot)\n\nboot_delta &lt;- function(data, indices) {\n  d &lt;- data[indices, ]\n  m &lt;- lm(y ~ x * group, data = d)\n  coef(m)[\"x:group\"]\n}\n\n# Use cluster-aware resampling if needed\nboot_out &lt;- boot(data_pooled, boot_delta, R = 2000)\nboot.ci(boot_out, type = \"perc\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comparing Estimates Correctly: Why 'Significant' vs 'Not Significant' Is Not a Difference</span>"
    ]
  },
  {
    "objectID": "chapters/Comparing_Estimates.html#appendix-b-which-method-when-cheat-sheet",
    "href": "chapters/Comparing_Estimates.html#appendix-b-which-method-when-cheat-sheet",
    "title": "4  Comparing Estimates Correctly: Why ‘Significant’ vs ‘Not Significant’ Is Not a Difference",
    "section": "4.10 Appendix B — “Which Method When?” Cheat Sheet",
    "text": "4.10 Appendix B — “Which Method When?” Cheat Sheet\n\n\n\nQuick reference: choosing a method for comparing estimates\n\n\n\n\n\n\n\nScenario\nRecommended Method\nKey Assumption\n\n\n\n\nIndependent samples, large N\nz-test with summed variances (Eq. 2)\nIndependence of samples\n\n\nIndependent samples, pooled model available\nPooled regression + interaction term\nCommon error variance or heteroskedasticity-robust SEs\n\n\nSame units, time split (panel)\nPooled panel model + period interaction, cluster SEs\nCorrect FE/RE specification, adequate clustering\n\n\nSame units, geographic or group split\nPooled model + group interaction, unit FE\nCorrect grouping, sufficient within-group variation\n\n\nOverlapping / nested samples\nCovariance-aware test (Eq. 3) or stacked/simultaneous model\nCorrect covariance estimation\n\n\nNonlinear model (logit, Poisson)\nCompare marginal effects or predicted probabilities, not raw coefficients\nCorrect specification of both models\n\n\nMany subgroup comparisons\nJoint F-test + multiple-comparison correction\nPre-specified subgroups; correction method chosen ex ante",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comparing Estimates Correctly: Why 'Significant' vs 'Not Significant' Is Not a Difference</span>"
    ]
  }
]